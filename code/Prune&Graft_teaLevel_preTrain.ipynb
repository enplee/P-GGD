{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.640959Z",
     "start_time": "2020-10-27T12:31:29.119435Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import collections\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import copy\n",
    "from thop import profile\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "import torch.utils\n",
    "import torch.utils.data.distributed\n",
    "from torchvision import datasets, transforms\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.667987Z",
     "start_time": "2020-10-27T12:31:29.641960Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled=True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.688007Z",
     "start_time": "2020-10-27T12:31:29.668988Z"
    },
    "code_folding": [
     3,
     9,
     15,
     18,
     19,
     52,
     58
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pdb\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, compress_rate, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t-ex, c-channel, n-blocknum, s-stride\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 1],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        self.compress_rate=compress_rate[:]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
    "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        cnt=1\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
    "            output_channel = int((1-self.compress_rate[cnt])*output_channel)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "            cnt+=1\n",
    "\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        #self.classifier = nn.Linear(self.last_channel, n_class)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenet_v2(compress_rate,n_class=1000):\n",
    "    model = MobileNetV2(compress_rate=compress_rate,n_class=n_class,width_mult=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.714033Z",
     "start_time": "2020-10-27T12:31:29.689008Z"
    },
    "code_folding": [
     1,
     27,
     29,
     31,
     34,
     35,
     41,
     88,
     89,
     153,
     156
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare resNet_50 model...\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare resNet_50 model...\")\n",
    "def adapt_channel(compress_rate, num_layers):\n",
    "\n",
    "    if num_layers==56:\n",
    "        stage_repeat = [9, 9, 9]\n",
    "        stage_out_channel = [16] + [16] * 9 + [32] * 9 + [64] * 9\n",
    "    elif num_layers==110:\n",
    "        stage_repeat = [18, 18, 18]\n",
    "        stage_out_channel = [16] + [16] * 18 + [32] * 18 + [64] * 18\n",
    "\n",
    "    stage_oup_cprate = []\n",
    "    stage_oup_cprate += [compress_rate[0]]\n",
    "    for i in range(len(stage_repeat)-1):\n",
    "        stage_oup_cprate += [compress_rate[i+1]] * stage_repeat[i]\n",
    "    stage_oup_cprate +=[0.] * stage_repeat[-1]\n",
    "    mid_cprate = compress_rate[len(stage_repeat):]\n",
    "\n",
    "    overall_channel = []\n",
    "    mid_channel = []\n",
    "    for i in range(len(stage_out_channel)):\n",
    "        if i == 0 :\n",
    "            overall_channel += [int(stage_out_channel[i] * (1-stage_oup_cprate[i]))]\n",
    "        else:\n",
    "            overall_channel += [int(stage_out_channel[i] * (1-stage_oup_cprate[i]))]\n",
    "            mid_channel += [int(stage_out_channel[i] * (1-mid_cprate[i-1]))]\n",
    "\n",
    "    return overall_channel, mid_channel\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, midplanes, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.conv1 = conv3x3(inplanes, midplanes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(midplanes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(midplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            if stride!=1:\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(x[:, :, ::2, ::2],\n",
    "                                    (0, 0, 0, 0, (planes-inplanes)//2, planes-inplanes-(planes-inplanes)//2), \"constant\", 0))\n",
    "            else:\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(x[:, :, :, :],\n",
    "                                    (0, 0, 0, 0, (planes-inplanes)//2, planes-inplanes-(planes-inplanes)//2), \"constant\", 0))\n",
    "            #self.shortcut = LambdaLayer(\n",
    "            #    lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4),\"constant\", 0))\n",
    "\n",
    "            '''self.shortcut = nn.Sequential(\n",
    "                conv1x1(inplanes, planes, stride=stride),\n",
    "                #nn.BatchNorm2d(planes),\n",
    "            )#'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        #print(self.stride, self.inplanes, self.planes, out.size(), self.shortcut(x).size())\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_layers, compress_rate, num_classes=9):\n",
    "        super(ResNet, self).__init__()\n",
    "        assert (num_layers - 2) % 6 == 0, 'depth should be 6n+2'\n",
    "        n = (num_layers - 2) // 6\n",
    "\n",
    "        self.num_layer = num_layers\n",
    "        self.overall_channel, self.mid_channel = adapt_channel(compress_rate, num_layers)\n",
    "\n",
    "        self.layer_num = 0\n",
    "        self.conv1 = nn.Conv2d(3, self.overall_channel[self.layer_num], kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.overall_channel[self.layer_num])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_num += 1\n",
    "\n",
    "        #self.layers = nn.ModuleList()\n",
    "        self.layer1 = self._make_layer(block, blocks_num=n, stride=1)\n",
    "        self.layer2 = self._make_layer(block, blocks_num=n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, blocks_num=n, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        if self.num_layer == 56:\n",
    "            self.fc = nn.Linear(64 * BasicBlock.expansion, num_classes)\n",
    "        else:\n",
    "            self.linear = nn.Linear(64 * BasicBlock.expansion, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, blocks_num, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.mid_channel[self.layer_num - 1], self.overall_channel[self.layer_num - 1],\n",
    "                                 self.overall_channel[self.layer_num], stride))\n",
    "        self.layer_num += 1\n",
    "\n",
    "        for i in range(1, blocks_num):\n",
    "            layers.append(block(self.mid_channel[self.layer_num - 1], self.overall_channel[self.layer_num - 1],\n",
    "                                     self.overall_channel[self.layer_num]))\n",
    "            self.layer_num += 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        for i, block in enumerate(self.layer1):\n",
    "            x = block(x)\n",
    "        for i, block in enumerate(self.layer2):\n",
    "            x = block(x)\n",
    "        for i, block in enumerate(self.layer3):\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.num_layer == 56:\n",
    "            x = self.fc(x)\n",
    "        else:\n",
    "            x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet_56(compress_rate):\n",
    "    return ResNet(BasicBlock, 56, compress_rate=compress_rate)\n",
    "\n",
    "def resnet_110(compress_rate):\n",
    "    return ResNet(BasicBlock, 110, compress_rate=compress_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.724044Z",
     "start_time": "2020-10-27T12:31:29.715034Z"
    },
    "code_folding": [
     3,
     51
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare vgg...\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare vgg...\")\n",
    "defaultcfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 8192, 512]\n",
    "relucfg = [2, 6, 9, 13, 16, 19, 23, 26, 29, 33, 36, 39]\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, compress_rate, cfg=None, num_classes=9):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        if cfg is None:\n",
    "            cfg = defaultcfg\n",
    "        self.relucfg = relucfg\n",
    "\n",
    "        self.compress_rate = compress_rate[:]\n",
    "        self.compress_rate.append(0.0)\n",
    "\n",
    "        self.features = self._make_layers(cfg)\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(cfg[-2], cfg[-1])),\n",
    "            ('norm1', nn.BatchNorm1d(cfg[-1])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('linear2', nn.Linear(cfg[-1], num_classes)),\n",
    "        ]))\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "\n",
    "        layers = nn.Sequential()\n",
    "        in_channels = 3\n",
    "        cnt=0\n",
    "\n",
    "        for i, x in enumerate(cfg):\n",
    "            if x == 'M':\n",
    "                layers.add_module('pool%d' % i, nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                x = int(x * (1-self.compress_rate[cnt]))\n",
    "\n",
    "                cnt+=1\n",
    "                conv2d = nn.Conv2d(in_channels, x, kernel_size=3, padding=1)\n",
    "                layers.add_module('conv%d' % i, conv2d)\n",
    "                layers.add_module('norm%d' % i, nn.BatchNorm2d(x))\n",
    "                layers.add_module('relu%d' % i, nn.ReLU(inplace=True))\n",
    "                in_channels = x\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "def vgg_16_bn(compress_rate):\n",
    "    return VGG(compress_rate=compress_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.743062Z",
     "start_time": "2020-10-27T12:31:29.725044Z"
    },
    "code_folding": [
     3,
     24,
     38,
     79,
     87,
     111
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare densent....\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare densent....\")\n",
    "norm_mean, norm_var = 0.0, 1.0\n",
    "cov_cfg=[(3*i+1) for i in range(12*3+2+1)]\n",
    "class DenseBasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, dropRate=0):\n",
    "        super(DenseBasicBlock, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "class DenseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, compress_rate, depth=40, block=DenseBasicBlock,\n",
    "        dropRate=0, num_classes=9, growthRate=12, compressionRate=1):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.compress_rate=compress_rate\n",
    "\n",
    "        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n",
    "        n = (depth - 4) // 3 if 'DenseBasicBlock' in str(block) else (depth - 4) // 6\n",
    "\n",
    "        transition = Transition\n",
    "\n",
    "        self.covcfg=cov_cfg\n",
    "\n",
    "        self.growthRate = growthRate\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "        self.inplanes = growthRate * 2\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "\n",
    "        self.dense1 = self._make_denseblock(block, n, compress_rate[1:n+1])\n",
    "        self.trans1 = self._make_transition(transition, compressionRate, compress_rate[n+1])\n",
    "        self.dense2 = self._make_denseblock(block, n, compress_rate[n+2:2*n+2])\n",
    "        self.trans2 = self._make_transition(transition, compressionRate, compress_rate[2*n+2])\n",
    "        self.dense3 = self._make_denseblock(block, n, compress_rate[2*n+3:3*n+3])\n",
    "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "\n",
    "        self.fc = nn.Linear(9*self.inplanes, num_classes)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_denseblock(self, block, blocks, compress_rate):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(self.inplanes, outplanes=int(self.growthRate*(1-compress_rate[i])), dropRate=self.dropRate))\n",
    "            self.inplanes += int(self.growthRate*(1-compress_rate[i]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_transition(self, transition, compressionRate, compress_rate):\n",
    "        inplanes = self.inplanes\n",
    "        outplanes = int(math.floor(self.inplanes*(1-compress_rate) // compressionRate))\n",
    "        self.inplanes = outplanes\n",
    "        return transition(inplanes, outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.trans1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.trans2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def densenet_40(compress_rate):\n",
    "    return DenseNet(compress_rate=compress_rate, depth=40, block=DenseBasicBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.762081Z",
     "start_time": "2020-10-27T12:31:29.744063Z"
    },
    "code_folding": [
     3,
     9,
     15,
     18,
     57,
     128
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building mobileNetV2 model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building mobileNetV2 model..')\n",
    "import math\n",
    "import pdb\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, compress_rate, n_class, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t-ex, c-channel, n-blocknum, s-stride\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 1], # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        self.compress_rate=compress_rate[:]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
    "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        cnt=1\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
    "            output_channel = int((1-self.compress_rate[cnt])*output_channel)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "            cnt+=1\n",
    "\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        #self.classifier = nn.Linear(self.last_channel, n_class)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenet_v2(compress_rate,n_class=9):\n",
    "    model = MobileNetV2(compress_rate=compress_rate,n_class=n_class,width_mult=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.793113Z",
     "start_time": "2020-10-27T12:31:29.763082Z"
    },
    "code_folding": [
     4,
     5,
     86,
     100
    ]
   },
   "outputs": [],
   "source": [
    "'''GoogLeNet with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "norm_mean, norm_var = 0.0, 1.0\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes,tmp_name, cp_rate, last=False):\n",
    "        super(Inception, self).__init__()\n",
    "        self.tmp_name=tmp_name\n",
    "\n",
    "        self.n1x1 = n1x1\n",
    "        self.n3x3 = n3x3\n",
    "        self.n5x5 = n5x5\n",
    "        self.pool_planes = pool_planes\n",
    "\n",
    "        # 1x1 conv branch\n",
    "        if self.n1x1:\n",
    "            conv1x1 = nn.Conv2d(in_planes, n1x1, kernel_size=1)\n",
    "            conv1x1.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch1x1 = nn.Sequential(\n",
    "                conv1x1,\n",
    "                nn.BatchNorm2d(n1x1),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        if self.n3x3:\n",
    "\n",
    "            if last:\n",
    "                output=n3x3\n",
    "            else:\n",
    "                output=int(n3x3*cp_rate)\n",
    "\n",
    "            conv3x3_1=nn.Conv2d(in_planes, n3x3red, kernel_size=1)\n",
    "            conv3x3_2=nn.Conv2d(n3x3red, output, kernel_size=3, padding=1)\n",
    "            conv3x3_1.tmp_name = self.tmp_name\n",
    "            conv3x3_2.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch3x3 = nn.Sequential(\n",
    "                conv3x3_1,\n",
    "                nn.BatchNorm2d(n3x3red),\n",
    "                nn.ReLU(True),\n",
    "                conv3x3_2,\n",
    "                nn.BatchNorm2d(output),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        if self.n5x5 > 0:\n",
    "\n",
    "            if last:\n",
    "                output=n5x5\n",
    "            else:\n",
    "                output=int(n5x5*cp_rate)\n",
    "\n",
    "            conv5x5_1 = nn.Conv2d(in_planes, n5x5red, kernel_size=1)\n",
    "            conv5x5_2 = nn.Conv2d(n5x5red, int(n5x5*cp_rate), kernel_size=3, padding=1)\n",
    "            conv5x5_3 = nn.Conv2d(int(n5x5*cp_rate), output, kernel_size=3, padding=1)\n",
    "            conv5x5_1.tmp_name = self.tmp_name\n",
    "            conv5x5_2.tmp_name = self.tmp_name\n",
    "            conv5x5_3.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch5x5 = nn.Sequential(\n",
    "                conv5x5_1,\n",
    "                nn.BatchNorm2d(n5x5red),\n",
    "                nn.ReLU(True),\n",
    "                conv5x5_2,\n",
    "                nn.BatchNorm2d(int(n5x5*cp_rate)),\n",
    "                nn.ReLU(True),\n",
    "                conv5x5_3,\n",
    "                nn.BatchNorm2d(output),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        if self.pool_planes > 0:\n",
    "            conv_pool = nn.Conv2d(in_planes, pool_planes, kernel_size=1)\n",
    "            conv_pool.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch_pool = nn.Sequential(\n",
    "                nn.MaxPool2d(3, stride=1, padding=1),\n",
    "                conv_pool,\n",
    "                nn.BatchNorm2d(pool_planes),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        y1 = self.branch1x1(x)\n",
    "        out.append(y1)\n",
    "\n",
    "        y2 = self.branch3x3(x)\n",
    "        out.append(y2)\n",
    "\n",
    "        y3 = self.branch5x5(x)\n",
    "        out.append(y3)\n",
    "\n",
    "        y4 = self.branch_pool(x)\n",
    "        out.append(y4)\n",
    "        return torch.cat(out, 1)\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, compress_rate, block=Inception, filters=None):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        first_outplanes=192\n",
    "        conv_pre = nn.Conv2d(3, first_outplanes, kernel_size=3, padding=1)\n",
    "        conv_pre.tmp_name = 'pre_layer'\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            conv_pre,\n",
    "            nn.BatchNorm2d(first_outplanes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        filters = [\n",
    "            [64, 128, 32, 32],\n",
    "            [128, 192, 96, 64],\n",
    "            [192, 208, 48, 64],\n",
    "            [160, 224, 64, 64],\n",
    "            [128, 256, 64, 64],\n",
    "            [112, 288, 64, 64],\n",
    "            [256, 320, 128, 128],\n",
    "            [256, 320, 128, 128],\n",
    "            [384, 384, 128, 128]\n",
    "        ]\n",
    "        self.filters = filters\n",
    "\n",
    "        mid_filters = [\n",
    "            [96, 16],\n",
    "            [128, 32],\n",
    "            [96, 16],\n",
    "            [112, 24],\n",
    "            [128, 24],\n",
    "            [144, 32],\n",
    "            [160, 32],\n",
    "            [160, 32],\n",
    "            [192, 48]\n",
    "        ]\n",
    "\n",
    "        cp_rate_list=[]\n",
    "        for cp_rate in compress_rate:\n",
    "            cp_rate_list.append(1-cp_rate)\n",
    "\n",
    "        in_plane_list=[]\n",
    "        for i in range(8):\n",
    "            in_plane_list.append(filters[i][0]+int(filters[i][1]*cp_rate_list[i+1])+int(filters[i][2]*cp_rate_list[i+1])+filters[i][3])\n",
    "\n",
    "        self.inception_a3 = block(first_outplanes, filters[0][0], mid_filters[0][0], filters[0][1], mid_filters[0][1], filters[0][2], filters[0][3], 'a3', cp_rate_list[1])\n",
    "        self.inception_b3 = block(in_plane_list[0], filters[1][0], mid_filters[1][0], filters[1][1], mid_filters[1][1], filters[1][2], filters[1][3], 'a4', cp_rate_list[2])\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_a4 = block(in_plane_list[1], filters[2][0], mid_filters[2][0], filters[2][1], mid_filters[2][1], filters[2][2], filters[2][3], 'a4', cp_rate_list[3])\n",
    "        self.inception_b4 = block(in_plane_list[2], filters[3][0], mid_filters[3][0], filters[3][1], mid_filters[3][1], filters[3][2], filters[3][3], 'b4', cp_rate_list[4])\n",
    "        self.inception_c4 = block(in_plane_list[3], filters[4][0], mid_filters[4][0], filters[4][1], mid_filters[4][1], filters[4][2], filters[4][3], 'c4', cp_rate_list[5])\n",
    "        self.inception_d4 = block(in_plane_list[4], filters[5][0], mid_filters[5][0], filters[5][1], mid_filters[5][1], filters[5][2], filters[5][3], 'd4', cp_rate_list[6])\n",
    "        self.inception_e4 = block(in_plane_list[5], filters[6][0], mid_filters[6][0], filters[6][1], mid_filters[6][1], filters[6][2], filters[6][3], 'e4', cp_rate_list[7])\n",
    "\n",
    "        self.inception_a5 = block(in_plane_list[6], filters[7][0], mid_filters[7][0], filters[7][1], mid_filters[7][1], filters[7][2], filters[7][3], 'a5', cp_rate_list[8])\n",
    "        self.inception_b5 = block(in_plane_list[7], filters[8][0], mid_filters[8][0], filters[8][1], mid_filters[8][1], filters[8][2], filters[8][3], 'b5', cp_rate_list[9], last=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.linear = nn.Linear(9*sum(filters[-1]), 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.pre_layers(x)\n",
    "\n",
    "        # 192 x 32 x 32\n",
    "        out = self.inception_a3(out)\n",
    "        # 256 x 32 x 32\n",
    "        out = self.inception_b3(out)\n",
    "        # 480 x 32 x 32\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # 480 x 16 x 16\n",
    "        out = self.inception_a4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_b4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_c4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_d4(out)\n",
    "        # 528 x 16 x 16\n",
    "        out = self.inception_e4(out)\n",
    "        # 823 x 16 x 16\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # 823 x 8 x 8\n",
    "        out = self.inception_a5(out)\n",
    "        # 823 x 8 x 8\n",
    "        out = self.inception_b5(out)\n",
    "\n",
    "        # 1024 x 8 x 8\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "def googlenet(compress_rate):\n",
    "    return GoogLeNet(compress_rate=compress_rate, block=Inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.798118Z",
     "start_time": "2020-10-27T12:31:29.794113Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "\n",
    "  def __init__(self, num_classes, epsilon):\n",
    "    super(CrossEntropyLabelSmooth, self).__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.epsilon = epsilon\n",
    "    self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, inputs, targets):\n",
    "    log_probs = self.logsoftmax(inputs)\n",
    "    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "    loss = (-targets * log_probs).mean(0).sum()\n",
    "    return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:29.802122Z",
     "start_time": "2020-10-27T12:31:29.799119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超参数\n"
     ]
    }
   ],
   "source": [
    "print(\"超参数\")\n",
    "arch = \"vgg\"\n",
    "CLASSES = 9\n",
    "epochs = 300\n",
    "batch_size=  16\n",
    "learning_rate = 0.005\n",
    "momentum = 0.9\n",
    "# 0.006\n",
    "weight_decay = 0.005\n",
    "lr_decay_step = '150,225'\n",
    "\n",
    "best_acc = 0\n",
    "# \"./data/teaLevel/singleLeaf/\"\n",
    "data_dir = \"./data/teaLevel/singleLeaf/\"\n",
    "save_dir = \"./data/model/Hrank_preTrain/teaLevel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:31.217546Z",
     "start_time": "2020-10-27T12:31:29.803122Z"
    }
   },
   "outputs": [],
   "source": [
    "if arch == \"resnet_56\":\n",
    "    net = resnet_56(compress_rate=[0.]*100)\n",
    "if arch ==  \"resnet_110\":\n",
    "    net = resnet_110(compress_rate=[0.]*100)\n",
    "if arch == \"vgg\":\n",
    "    net = vgg_16_bn(compress_rate=[0.]*100)\n",
    "if arch == \"densnet\":\n",
    "    net = densenet_40(compress_rate=[0.]*100)\n",
    "if arch == \"mobilenetV2\":\n",
    "    net = mobilenet_v2(compress_rate=[0.]*100)\n",
    "if arch == \"goolenet\":\n",
    "    net = googlenet(compress_rate=[0.]*100)\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "criterion_smooth = CrossEntropyLabelSmooth(CLASSES, 0.1)\n",
    "criterion_smooth = criterion_smooth.cuda()\n",
    "\n",
    "lr_decay_step = list(map(int, lr_decay_step.split(',')))\n",
    "optimizer = torch.optim.SGD(net.parameters(), learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=60, gamma=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_decay_step, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:31.241570Z",
     "start_time": "2020-10-27T12:31:31.218546Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load training data\n"
     ]
    }
   ],
   "source": [
    "print('load training data')\n",
    "# transforms.RandomResizedCrop(104),\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]),\n",
    "    \"val\": transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=data_dir+\"train\",transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "tea_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in tea_list.items())\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "# batch_size = 128  \n",
    "trainloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=data_dir + \"val\",transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "testloader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:31.247576Z",
     "start_time": "2020-10-27T12:31:31.242571Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "lr_type = 'step'\n",
    "def adjust_learning_rate(optimizer, epoch, step, len_iter):\n",
    "\n",
    "    if lr_type == 'step':\n",
    "        factor = epoch // 30\n",
    "        if epoch >= 80:\n",
    "            factor = factor + 1\n",
    "        lr = learning_rate * (0.1 ** factor)\n",
    "\n",
    "    elif lr_type == 'cos':  # cos without warm-up\n",
    "        lr = 0.5 * learning_rate * (1 + math.cos(math.pi * (epoch - 5) / (epochs - 5)))\n",
    "\n",
    "    elif lr_type == 'exp':\n",
    "        step = 1\n",
    "        decay = 0.96\n",
    "        lr = learning_rate * (decay ** (epoch // step))\n",
    "\n",
    "    elif lr_type == 'fixed':\n",
    "        lr = learning_rate\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    #Warmup\n",
    "    if epoch < 5:\n",
    "        lr = lr * float(1 + step + epoch * len_iter) / (5. * len_iter)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    if step == 0:\n",
    "        print('learning_rate: ' + str(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T12:31:31.256585Z",
     "start_time": "2020-10-27T12:31:31.248577Z"
    },
    "code_folding": [
     25
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch,i,net,optimizer,scheduler):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_iter = len(trainloader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch, batch_idx, num_iter)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 1000 == 1000 - 1 or 1000 == trainloader.__len__() - 1:\n",
    "            print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "                train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "    scheduler.step()\n",
    "    \n",
    "def test(epoch,net,i):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100. * correct / total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc\n",
    "        }\n",
    "        torch.save(state, save_dir+'best_%d.t7' % (epoch))\n",
    "    print('Network:%d    epoch:%d    accuracy:%.3f    best:%.3f' % (i, epoch, acc, best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T15:54:46.621895Z",
     "start_time": "2020-10-27T12:31:31.257586Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU(inplace=True)\n",
      "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu4): ReLU(inplace=True)\n",
      "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu6): ReLU(inplace=True)\n",
      "    (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu7): ReLU(inplace=True)\n",
      "    (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu8): ReLU(inplace=True)\n",
      "    (pool9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv10): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu10): ReLU(inplace=True)\n",
      "    (conv11): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu11): ReLU(inplace=True)\n",
      "    (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu12): ReLU(inplace=True)\n",
      "    (pool13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu14): ReLU(inplace=True)\n",
      "    (conv15): Conv2d(512, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm15): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu15): ReLU(inplace=True)\n",
      "    (conv16): Conv2d(8192, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (norm16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu16): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (linear1): Linear(in_features=8192, out_features=512, bias=True)\n",
      "    (norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace=True)\n",
      "    (linear2): Linear(in_features=512, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "learning_rate: 5.376344086021506e-06\n",
      "Network:1    epoch:0    accuracy:21.296    best:21.296\n",
      "learning_rate: 0.0010053763440860215\n",
      "Network:1    epoch:1    accuracy:17.901    best:21.296\n",
      "learning_rate: 0.0020053763440860215\n",
      "Network:1    epoch:2    accuracy:23.457    best:23.457\n",
      "learning_rate: 0.0030053763440860215\n",
      "Network:1    epoch:3    accuracy:29.630    best:29.630\n",
      "learning_rate: 0.0040053763440860216\n",
      "Network:1    epoch:4    accuracy:28.086    best:29.630\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:5    accuracy:24.074    best:29.630\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:6    accuracy:28.704    best:29.630\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:7    accuracy:21.605    best:29.630\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:8    accuracy:54.012    best:54.012\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:9    accuracy:63.580    best:63.580\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:10    accuracy:22.531    best:63.580\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:11    accuracy:32.716    best:63.580\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:12    accuracy:56.790    best:63.580\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:13    accuracy:23.765    best:63.580\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:14    accuracy:68.827    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:15    accuracy:54.938    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:16    accuracy:35.185    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:17    accuracy:41.358    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:18    accuracy:29.321    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:19    accuracy:35.802    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:20    accuracy:65.741    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:21    accuracy:35.802    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:22    accuracy:56.790    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:23    accuracy:48.148    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:24    accuracy:51.235    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:25    accuracy:40.123    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:26    accuracy:40.741    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:27    accuracy:51.235    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:28    accuracy:52.160    best:68.827\n",
      "learning_rate: 0.005\n",
      "Network:1    epoch:29    accuracy:48.765    best:68.827\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:30    accuracy:89.198    best:89.198\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:31    accuracy:89.506    best:89.506\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:32    accuracy:90.741    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:33    accuracy:87.963    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:34    accuracy:88.272    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:35    accuracy:89.506    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:36    accuracy:89.506    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:37    accuracy:87.963    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:38    accuracy:89.506    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:39    accuracy:89.198    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:40    accuracy:90.123    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:41    accuracy:88.889    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:42    accuracy:90.123    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:43    accuracy:89.506    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:44    accuracy:90.741    best:90.741\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:45    accuracy:91.667    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:46    accuracy:89.198    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:47    accuracy:89.198    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:48    accuracy:91.667    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:49    accuracy:88.272    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:50    accuracy:89.198    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:51    accuracy:84.259    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:52    accuracy:88.889    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:53    accuracy:86.420    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:54    accuracy:90.123    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:55    accuracy:84.259    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:56    accuracy:87.654    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:57    accuracy:89.506    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:58    accuracy:88.889    best:91.667\n",
      "learning_rate: 0.0005\n",
      "Network:1    epoch:59    accuracy:87.346    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:60    accuracy:89.198    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:61    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:62    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:63    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:64    accuracy:89.198    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:65    accuracy:90.123    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:66    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:67    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:68    accuracy:90.741    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:69    accuracy:91.667    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:70    accuracy:89.815    best:91.667\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:71    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:72    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:73    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:74    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:75    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:76    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:77    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:78    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-05\n",
      "Network:1    epoch:79    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:80    accuracy:89.815    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:81    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:82    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:83    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:84    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:85    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:86    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:87    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:88    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-06\n",
      "Network:1    epoch:89    accuracy:89.198    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:90    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:91    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:92    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:93    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:94    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:95    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:96    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:97    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:98    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:99    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:100    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:101    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:102    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:103    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:104    accuracy:89.815    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:105    accuracy:88.889    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:106    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:107    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:108    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:109    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:110    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:111    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:112    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:113    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:114    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:115    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:116    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:117    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:118    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-07\n",
      "Network:1    epoch:119    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:120    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:121    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:122    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:123    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:124    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:125    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:126    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:127    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:128    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:129    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:130    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:131    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:132    accuracy:89.815    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:133    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:134    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:135    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:136    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:137    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:138    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:139    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:140    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:141    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:142    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:143    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:144    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:145    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:146    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:147    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n",
      "Network:1    epoch:148    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000001e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:149    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:150    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:151    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:152    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:153    accuracy:89.815    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:154    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:155    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:156    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:157    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:158    accuracy:89.815    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:159    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:160    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:161    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:162    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:163    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:164    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:165    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:166    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:167    accuracy:91.975    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:168    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:169    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:170    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:171    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:172    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:173    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:174    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:175    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:176    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:177    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:178    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-09\n",
      "Network:1    epoch:179    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:180    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:181    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:182    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:183    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:184    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:185    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:186    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:187    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:188    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:189    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:190    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:191    accuracy:91.049    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:192    accuracy:91.358    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:193    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:194    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:195    accuracy:91.667    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:196    accuracy:90.123    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:197    accuracy:90.432    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:198    accuracy:90.741    best:91.975\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:199    accuracy:92.284    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:200    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:201    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:202    accuracy:89.815    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:203    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:204    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:205    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:206    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:207    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:208    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000002e-10\n",
      "Network:1    epoch:209    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:210    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:211    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:212    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:213    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:214    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:215    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:216    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:217    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:218    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:219    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:220    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:221    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:222    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:223    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:224    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:225    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:226    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:227    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:228    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:229    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:230    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:231    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:232    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:233    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:234    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:235    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:236    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:237    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:238    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-11\n",
      "Network:1    epoch:239    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:240    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:241    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:242    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:243    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:244    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:245    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:246    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:247    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:248    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:249    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:250    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:251    accuracy:89.506    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:252    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:253    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:254    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:255    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:256    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:257    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:258    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:259    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:260    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:261    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:262    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:263    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:264    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:265    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:266    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:267    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:268    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000002e-12\n",
      "Network:1    epoch:269    accuracy:92.284    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:270    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:271    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:272    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:273    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:274    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:275    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:276    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:277    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:278    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:279    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:280    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:281    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:282    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:283    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:284    accuracy:92.284    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:285    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:286    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:287    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:288    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:289    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:290    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:291    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:292    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:293    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:294    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:295    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:296    accuracy:89.815    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:297    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:298    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-13\n",
      "Network:1    epoch:299    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:300    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:301    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:302    accuracy:89.506    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:303    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:304    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:305    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:306    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:307    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:308    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:309    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:310    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:311    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:312    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:313    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:314    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:315    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:316    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:317    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:318    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:319    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:320    accuracy:92.284    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:321    accuracy:89.815    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:322    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:323    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:324    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:325    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:326    accuracy:89.198    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:327    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:328    accuracy:92.284    best:92.284\n",
      "learning_rate: 5.000000000000003e-14\n",
      "Network:1    epoch:329    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:330    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:331    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:332    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:333    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:334    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:335    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:336    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:337    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:338    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:339    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:340    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:341    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:342    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:343    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:344    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:345    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:346    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:347    accuracy:89.198    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:348    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:349    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:350    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:351    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:352    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:353    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:354    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:355    accuracy:89.506    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:356    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:357    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:358    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-15\n",
      "Network:1    epoch:359    accuracy:88.889    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:360    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:361    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:362    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:363    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:364    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:365    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:366    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:367    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:368    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:369    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:370    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:371    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:372    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:373    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:374    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:375    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:376    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:377    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:378    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:379    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:380    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:381    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:382    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:383    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:384    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:385    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:386    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:387    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:388    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000003e-16\n",
      "Network:1    epoch:389    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:390    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:391    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:392    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:393    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:394    accuracy:89.506    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:395    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:396    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:397    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:398    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:399    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:400    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:401    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:402    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:403    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:404    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:405    accuracy:89.198    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:406    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:407    accuracy:91.049    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:408    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:409    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:410    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:411    accuracy:90.123    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:412    accuracy:90.432    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:413    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:414    accuracy:90.741    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:415    accuracy:91.667    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:416    accuracy:91.975    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:417    accuracy:91.358    best:92.284\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:418    accuracy:92.901    best:92.901\n",
      "learning_rate: 5.000000000000004e-17\n",
      "Network:1    epoch:419    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:420    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:421    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:422    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:423    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:424    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:425    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:426    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:427    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:428    accuracy:89.815    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:429    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:430    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:431    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:432    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:433    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:434    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:435    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:436    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:437    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:438    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:439    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:440    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:441    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:442    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:443    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:444    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:445    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:446    accuracy:92.284    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:447    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:448    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-18\n",
      "Network:1    epoch:449    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:450    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:451    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:452    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:453    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:454    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:455    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:456    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:457    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:458    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:459    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:460    accuracy:92.284    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:461    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:462    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:463    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:464    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:465    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:466    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:467    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:468    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:469    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:470    accuracy:89.506    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:471    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:472    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:473    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:474    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:475    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:476    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:477    accuracy:89.815    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:478    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000004e-19\n",
      "Network:1    epoch:479    accuracy:91.358    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:480    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:481    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:482    accuracy:89.815    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:483    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:484    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:485    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:486    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:487    accuracy:91.667    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:488    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:489    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:490    accuracy:89.815    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:491    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:492    accuracy:89.198    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:493    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:494    accuracy:91.975    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:495    accuracy:90.432    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:496    accuracy:91.049    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:497    accuracy:90.123    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:498    accuracy:90.741    best:92.901\n",
      "learning_rate: 5.000000000000005e-20\n",
      "Network:1    epoch:499    accuracy:91.667    best:92.901\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "for epoch in range(500):\n",
    "    train(epoch,1,net,optimizer,scheduler)\n",
    "    test(epoch,net,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
