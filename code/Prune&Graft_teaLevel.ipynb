{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:25.898954Z",
     "start_time": "2020-11-04T01:41:25.215237Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import collections\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import copy\n",
    "from thop import profile\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "import torch.utils\n",
    "import torch.utils.data.distributed\n",
    "from torchvision import datasets, transforms\n",
    "import json\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:25.918975Z",
     "start_time": "2020-11-04T01:41:25.899955Z"
    },
    "code_folding": [
     3,
     9,
     15,
     18,
     19,
     58,
     128
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building mobileNetV2 model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building mobileNetV2 model..')\n",
    "import math\n",
    "import pdb\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, compress_rate, n_class, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t-ex, c-channel, n-blocknum, s-stride\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 1], # NOTE: change stride 2 -> 1 for CIFAR10\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        self.compress_rate=compress_rate[:]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
    "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        cnt=1\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
    "            output_channel = int((1-self.compress_rate[cnt])*output_channel)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "            cnt+=1\n",
    "\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        #self.classifier = nn.Linear(self.last_channel, n_class)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenet_v2(compress_rate,n_class=9):\n",
    "    model = MobileNetV2(compress_rate=compress_rate,n_class=n_class,width_mult=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:26.557644Z",
     "start_time": "2020-11-04T01:41:26.534620Z"
    },
    "code_folding": [
     1,
     27,
     29,
     31,
     34,
     39,
     41,
     88,
     153,
     156
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare resNet_50 model...\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare resNet_50 model...\")\n",
    "def adapt_channel(compress_rate, num_layers):\n",
    "\n",
    "    if num_layers==56:\n",
    "        stage_repeat = [9, 9, 9]\n",
    "        stage_out_channel = [16] + [16] * 9 + [32] * 9 + [64] * 9\n",
    "    elif num_layers==110:\n",
    "        stage_repeat = [18, 18, 18]\n",
    "        stage_out_channel = [16] + [16] * 18 + [32] * 18 + [64] * 18\n",
    "\n",
    "    stage_oup_cprate = []\n",
    "    stage_oup_cprate += [compress_rate[0]]\n",
    "    for i in range(len(stage_repeat)-1):\n",
    "        stage_oup_cprate += [compress_rate[i+1]] * stage_repeat[i]\n",
    "    stage_oup_cprate +=[0.] * stage_repeat[-1]\n",
    "    mid_cprate = compress_rate[len(stage_repeat):]\n",
    "\n",
    "    overall_channel = []\n",
    "    mid_channel = []\n",
    "    for i in range(len(stage_out_channel)):\n",
    "        if i == 0 :\n",
    "            overall_channel += [int(stage_out_channel[i] * (1-stage_oup_cprate[i]))]\n",
    "        else:\n",
    "            overall_channel += [int(stage_out_channel[i] * (1-stage_oup_cprate[i]))]\n",
    "            mid_channel += [int(stage_out_channel[i] * (1-mid_cprate[i-1]))]\n",
    "\n",
    "    return overall_channel, mid_channel\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, midplanes, inplanes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "        self.conv1 = conv3x3(inplanes, midplanes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(midplanes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(midplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            if stride!=1:\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(x[:, :, ::2, ::2],\n",
    "                                    (0, 0, 0, 0, (planes-inplanes)//2, planes-inplanes-(planes-inplanes)//2), \"constant\", 0))\n",
    "            else:\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(x[:, :, :, :],\n",
    "                                    (0, 0, 0, 0, (planes-inplanes)//2, planes-inplanes-(planes-inplanes)//2), \"constant\", 0))\n",
    "            #self.shortcut = LambdaLayer(\n",
    "            #    lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4),\"constant\", 0))\n",
    "\n",
    "            '''self.shortcut = nn.Sequential(\n",
    "                conv1x1(inplanes, planes, stride=stride),\n",
    "                #nn.BatchNorm2d(planes),\n",
    "            )#'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        #print(self.stride, self.inplanes, self.planes, out.size(), self.shortcut(x).size())\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_layers, compress_rate, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        assert (num_layers - 2) % 6 == 0, 'depth should be 6n+2'\n",
    "        n = (num_layers - 2) // 6\n",
    "\n",
    "        self.num_layer = num_layers\n",
    "        self.overall_channel, self.mid_channel = adapt_channel(compress_rate, num_layers)\n",
    "\n",
    "        self.layer_num = 0\n",
    "        self.conv1 = nn.Conv2d(3, self.overall_channel[self.layer_num], kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.overall_channel[self.layer_num])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_num += 1\n",
    "\n",
    "        #self.layers = nn.ModuleList()\n",
    "        self.layer1 = self._make_layer(block, blocks_num=n, stride=1)\n",
    "        self.layer2 = self._make_layer(block, blocks_num=n, stride=2)\n",
    "        self.layer3 = self._make_layer(block, blocks_num=n, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        if self.num_layer == 56:\n",
    "            self.fc = nn.Linear(64 * BasicBlock.expansion, num_classes)\n",
    "        else:\n",
    "            self.linear = nn.Linear(64 * BasicBlock.expansion, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, blocks_num, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.mid_channel[self.layer_num - 1], self.overall_channel[self.layer_num - 1],\n",
    "                                 self.overall_channel[self.layer_num], stride))\n",
    "        self.layer_num += 1\n",
    "\n",
    "        for i in range(1, blocks_num):\n",
    "            layers.append(block(self.mid_channel[self.layer_num - 1], self.overall_channel[self.layer_num - 1],\n",
    "                                     self.overall_channel[self.layer_num]))\n",
    "            self.layer_num += 1\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        for i, block in enumerate(self.layer1):\n",
    "            x = block(x)\n",
    "        for i, block in enumerate(self.layer2):\n",
    "            x = block(x)\n",
    "        for i, block in enumerate(self.layer3):\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if self.num_layer == 56:\n",
    "            x = self.fc(x)\n",
    "        else:\n",
    "            x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def resnet_56(compress_rate,num_classes):\n",
    "    return ResNet(BasicBlock, 56, compress_rate,num_classes)\n",
    "\n",
    "def resnet_110(compress_rate,num_classes):\n",
    "    return ResNet(BasicBlock, 110, compress_rate,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:27.286408Z",
     "start_time": "2020-11-04T01:41:27.277398Z"
    },
    "code_folding": [
     3,
     50
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare vgg...\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare vgg...\")\n",
    "defaultcfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 8192, 512]\n",
    "relucfg = [2, 6, 9, 13, 16, 19, 23, 26, 29, 33, 36, 39]\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, compress_rate, cfg=None, num_classes=9):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        if cfg is None:\n",
    "            cfg = defaultcfg\n",
    "        self.relucfg = relucfg\n",
    "\n",
    "        self.compress_rate = compress_rate[:]\n",
    "        self.compress_rate.append(0.0)\n",
    "\n",
    "        self.features = self._make_layers(cfg)\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(cfg[-2], cfg[-1])),\n",
    "            ('norm1', nn.BatchNorm1d(cfg[-1])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('linear2', nn.Linear(cfg[-1], num_classes)),\n",
    "        ]))\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "\n",
    "        layers = nn.Sequential()\n",
    "        in_channels = 3\n",
    "        cnt=0\n",
    "\n",
    "        for i, x in enumerate(cfg):\n",
    "            if x == 'M':\n",
    "                layers.add_module('pool%d' % i, nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                x = int(x * (1-self.compress_rate[cnt]))\n",
    "\n",
    "                cnt+=1\n",
    "                conv2d = nn.Conv2d(in_channels, x, kernel_size=3, padding=1)\n",
    "                layers.add_module('conv%d' % i, conv2d)\n",
    "                layers.add_module('norm%d' % i, nn.BatchNorm2d(x))\n",
    "                layers.add_module('relu%d' % i, nn.ReLU(inplace=True))\n",
    "                in_channels = x\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x  \n",
    "def vgg_16_bn(compress_rate):\n",
    "    return VGG(compress_rate=compress_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:28.148311Z",
     "start_time": "2020-11-04T01:41:28.131293Z"
    },
    "code_folding": [
     3,
     24,
     38,
     111
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare densent....\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare densent....\")\n",
    "norm_mean, norm_var = 0.0, 1.0\n",
    "cov_cfg=[(3*i+1) for i in range(12*3+2+1)]\n",
    "class DenseBasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes, dropRate=0):\n",
    "        super(DenseBasicBlock, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        if self.dropRate > 0:\n",
    "            out = F.dropout(out, p=self.dropRate, training=self.training)\n",
    "\n",
    "        out = torch.cat((x, out), 1)\n",
    "\n",
    "        return out\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, inplanes, outplanes):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(inplanes, outplanes, kernel_size=1,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "class DenseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, compress_rate, depth=40, block=DenseBasicBlock,\n",
    "        dropRate=0, num_classes=9, growthRate=12, compressionRate=1):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.compress_rate=compress_rate\n",
    "\n",
    "        assert (depth - 4) % 3 == 0, 'depth should be 3n+4'\n",
    "        n = (depth - 4) // 3 if 'DenseBasicBlock' in str(block) else (depth - 4) // 6\n",
    "\n",
    "        transition = Transition\n",
    "\n",
    "        self.covcfg=cov_cfg\n",
    "\n",
    "        self.growthRate = growthRate\n",
    "        self.dropRate = dropRate\n",
    "\n",
    "        self.inplanes = growthRate * 2\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "\n",
    "        self.dense1 = self._make_denseblock(block, n, compress_rate[1:n+1])\n",
    "        self.trans1 = self._make_transition(transition, compressionRate, compress_rate[n+1])\n",
    "        self.dense2 = self._make_denseblock(block, n, compress_rate[n+2:2*n+2])\n",
    "        self.trans2 = self._make_transition(transition, compressionRate, compress_rate[2*n+2])\n",
    "        self.dense3 = self._make_denseblock(block, n, compress_rate[2*n+3:3*n+3])\n",
    "        self.bn = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AvgPool2d(8)\n",
    "\n",
    "        self.fc = nn.Linear(self.inplanes, num_classes)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_denseblock(self, block, blocks, compress_rate):\n",
    "        layers = []\n",
    "        for i in range(blocks):\n",
    "            layers.append(block(self.inplanes, outplanes=int(self.growthRate*(1-compress_rate[i])), dropRate=self.dropRate))\n",
    "            self.inplanes += int(self.growthRate*(1-compress_rate[i]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_transition(self, transition, compressionRate, compress_rate):\n",
    "        inplanes = self.inplanes\n",
    "        outplanes = int(math.floor(self.inplanes*(1-compress_rate) // compressionRate))\n",
    "        self.inplanes = outplanes\n",
    "        return transition(inplanes, outplanes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.trans1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.trans2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def densenet_40(compress_rate):\n",
    "    return DenseNet(compress_rate=compress_rate, depth=40, block=DenseBasicBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:28.892090Z",
     "start_time": "2020-11-04T01:41:28.840035Z"
    },
    "code_folding": [
     3,
     99,
     199
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare googlenet...\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare googlenet...\")\n",
    "'''GoogLeNet with PyTorch.'''\n",
    "norm_mean, norm_var = 0.0, 1.0\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes,tmp_name, cp_rate, last=False):\n",
    "        super(Inception, self).__init__()\n",
    "        self.tmp_name=tmp_name\n",
    "\n",
    "        self.n1x1 = n1x1\n",
    "        self.n3x3 = n3x3\n",
    "        self.n5x5 = n5x5\n",
    "        self.pool_planes = pool_planes\n",
    "\n",
    "        # 1x1 conv branch\n",
    "        if self.n1x1:\n",
    "            conv1x1 = nn.Conv2d(in_planes, n1x1, kernel_size=1)\n",
    "            conv1x1.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch1x1 = nn.Sequential(\n",
    "                conv1x1,\n",
    "                nn.BatchNorm2d(n1x1),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        if self.n3x3:\n",
    "\n",
    "            if last:\n",
    "                output=n3x3\n",
    "            else:\n",
    "                output=int(n3x3*cp_rate)\n",
    "\n",
    "            conv3x3_1=nn.Conv2d(in_planes, n3x3red, kernel_size=1)\n",
    "            conv3x3_2=nn.Conv2d(n3x3red, output, kernel_size=3, padding=1)\n",
    "            conv3x3_1.tmp_name = self.tmp_name\n",
    "            conv3x3_2.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch3x3 = nn.Sequential(\n",
    "                conv3x3_1,\n",
    "                nn.BatchNorm2d(n3x3red),\n",
    "                nn.ReLU(True),\n",
    "                conv3x3_2,\n",
    "                nn.BatchNorm2d(output),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        if self.n5x5 > 0:\n",
    "\n",
    "            if last:\n",
    "                output=n5x5\n",
    "            else:\n",
    "                output=int(n5x5*cp_rate)\n",
    "\n",
    "            conv5x5_1 = nn.Conv2d(in_planes, n5x5red, kernel_size=1)\n",
    "            conv5x5_2 = nn.Conv2d(n5x5red, int(n5x5*cp_rate), kernel_size=3, padding=1)\n",
    "            conv5x5_3 = nn.Conv2d(int(n5x5*cp_rate), output, kernel_size=3, padding=1)\n",
    "            conv5x5_1.tmp_name = self.tmp_name\n",
    "            conv5x5_2.tmp_name = self.tmp_name\n",
    "            conv5x5_3.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch5x5 = nn.Sequential(\n",
    "                conv5x5_1,\n",
    "                nn.BatchNorm2d(n5x5red),\n",
    "                nn.ReLU(True),\n",
    "                conv5x5_2,\n",
    "                nn.BatchNorm2d(int(n5x5*cp_rate)),\n",
    "                nn.ReLU(True),\n",
    "                conv5x5_3,\n",
    "                nn.BatchNorm2d(output),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        if self.pool_planes > 0:\n",
    "            conv_pool = nn.Conv2d(in_planes, pool_planes, kernel_size=1)\n",
    "            conv_pool.tmp_name = self.tmp_name\n",
    "\n",
    "            self.branch_pool = nn.Sequential(\n",
    "                nn.MaxPool2d(3, stride=1, padding=1),\n",
    "                conv_pool,\n",
    "                nn.BatchNorm2d(pool_planes),\n",
    "                nn.ReLU(True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        y1 = self.branch1x1(x)\n",
    "        out.append(y1)\n",
    "\n",
    "        y2 = self.branch3x3(x)\n",
    "        out.append(y2)\n",
    "\n",
    "        y3 = self.branch5x5(x)\n",
    "        out.append(y3)\n",
    "\n",
    "        y4 = self.branch_pool(x)\n",
    "        out.append(y4)\n",
    "        return torch.cat(out, 1)\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, compress_rate, block=Inception, filters=None):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        first_outplanes=192\n",
    "        conv_pre = nn.Conv2d(3, first_outplanes, kernel_size=3, padding=1)\n",
    "        conv_pre.tmp_name = 'pre_layer'\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            conv_pre,\n",
    "            nn.BatchNorm2d(first_outplanes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        filters = [\n",
    "            [64, 128, 32, 32],\n",
    "            [128, 192, 96, 64],\n",
    "            [192, 208, 48, 64],\n",
    "            [160, 224, 64, 64],\n",
    "            [128, 256, 64, 64],\n",
    "            [112, 288, 64, 64],\n",
    "            [256, 320, 128, 128],\n",
    "            [256, 320, 128, 128],\n",
    "            [384, 384, 128, 128]\n",
    "        ]\n",
    "        self.filters = filters\n",
    "\n",
    "        mid_filters = [\n",
    "            [96, 16],\n",
    "            [128, 32],\n",
    "            [96, 16],\n",
    "            [112, 24],\n",
    "            [128, 24],\n",
    "            [144, 32],\n",
    "            [160, 32],\n",
    "            [160, 32],\n",
    "            [192, 48]\n",
    "        ]\n",
    "\n",
    "        cp_rate_list=[]\n",
    "        for cp_rate in compress_rate:\n",
    "            cp_rate_list.append(1-cp_rate)\n",
    "\n",
    "        in_plane_list=[]\n",
    "        for i in range(8):\n",
    "            in_plane_list.append(filters[i][0]+int(filters[i][1]*cp_rate_list[i+1])+int(filters[i][2]*cp_rate_list[i+1])+filters[i][3])\n",
    "\n",
    "        self.inception_a3 = block(first_outplanes, filters[0][0], mid_filters[0][0], filters[0][1], mid_filters[0][1], filters[0][2], filters[0][3], 'a3', cp_rate_list[1])\n",
    "        self.inception_b3 = block(in_plane_list[0], filters[1][0], mid_filters[1][0], filters[1][1], mid_filters[1][1], filters[1][2], filters[1][3], 'a4', cp_rate_list[2])\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        self.inception_a4 = block(in_plane_list[1], filters[2][0], mid_filters[2][0], filters[2][1], mid_filters[2][1], filters[2][2], filters[2][3], 'a4', cp_rate_list[3])\n",
    "        self.inception_b4 = block(in_plane_list[2], filters[3][0], mid_filters[3][0], filters[3][1], mid_filters[3][1], filters[3][2], filters[3][3], 'b4', cp_rate_list[4])\n",
    "        self.inception_c4 = block(in_plane_list[3], filters[4][0], mid_filters[4][0], filters[4][1], mid_filters[4][1], filters[4][2], filters[4][3], 'c4', cp_rate_list[5])\n",
    "        self.inception_d4 = block(in_plane_list[4], filters[5][0], mid_filters[5][0], filters[5][1], mid_filters[5][1], filters[5][2], filters[5][3], 'd4', cp_rate_list[6])\n",
    "        self.inception_e4 = block(in_plane_list[5], filters[6][0], mid_filters[6][0], filters[6][1], mid_filters[6][1], filters[6][2], filters[6][3], 'e4', cp_rate_list[7])\n",
    "\n",
    "        self.inception_a5 = block(in_plane_list[6], filters[7][0], mid_filters[7][0], filters[7][1], mid_filters[7][1], filters[7][2], filters[7][3], 'a5', cp_rate_list[8])\n",
    "        self.inception_b5 = block(in_plane_list[7], filters[8][0], mid_filters[8][0], filters[8][1], mid_filters[8][1], filters[8][2], filters[8][3], 'b5', cp_rate_list[9], last=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.linear = nn.Linear(sum(filters[-1]), 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.pre_layers(x)\n",
    "\n",
    "        # 192 x 32 x 32\n",
    "        out = self.inception_a3(out)\n",
    "        # 256 x 32 x 32\n",
    "        out = self.inception_b3(out)\n",
    "        # 480 x 32 x 32\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # 480 x 16 x 16\n",
    "        out = self.inception_a4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_b4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_c4(out)\n",
    "        # 512 x 16 x 16\n",
    "        out = self.inception_d4(out)\n",
    "        # 528 x 16 x 16\n",
    "        out = self.inception_e4(out)\n",
    "        # 823 x 16 x 16\n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # 823 x 8 x 8\n",
    "        out = self.inception_a5(out)\n",
    "        # 823 x 8 x 8\n",
    "        out = self.inception_b5(out)\n",
    "\n",
    "        # 1024 x 8 x 8\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "def googlenet(compress_rate):\n",
    "    return GoogLeNet(compress_rate=compress_rate, block=Inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:29.825067Z",
     "start_time": "2020-11-04T01:41:29.786027Z"
    },
    "code_folding": [
     0,
     217,
     238,
     287
    ]
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "def load_mobilenetv2_model(model, oristate_dict):\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    last_select_index = None\n",
    "\n",
    "    all_honey_conv_weight = []\n",
    "\n",
    "    bn_part_name=['.weight','.bias','.running_mean','.running_var']\n",
    "    prefix = rank_conv_prefix+'rank_conv'\n",
    "    subfix = \".npy\"\n",
    "\n",
    "    layer_cnt=1\n",
    "    conv_cnt=1\n",
    "    cfg=[1,2,3,4,3,3,1,1]\n",
    "    for layer, num in enumerate(cfg):\n",
    "        if layer_cnt==1:\n",
    "            conv_id=[0,3]\n",
    "        elif layer_cnt==18:\n",
    "            conv_id=[0]\n",
    "        else:\n",
    "            conv_id=[0,3,6]\n",
    "\n",
    "        for k in range(num):\n",
    "            if layer_cnt==18:\n",
    "                block_name = 'features.' + str(layer_cnt) + '.'\n",
    "            else:\n",
    "                block_name = 'features.'+str(layer_cnt)+'.conv.'\n",
    "\n",
    "            for l in conv_id:\n",
    "                conv_cnt += 1\n",
    "                conv_name = block_name + str(l)\n",
    "                bn_name = block_name + str(l+1)\n",
    "\n",
    "                conv_weight_name = conv_name + '.weight'\n",
    "                all_honey_conv_weight.append(conv_weight_name)\n",
    "                oriweight = oristate_dict[conv_weight_name]\n",
    "                curweight = state_dict[name_base+conv_weight_name]\n",
    "                orifilter_num = oriweight.size(0)\n",
    "                currentfilter_num = curweight.size(0)\n",
    "\n",
    "                if orifilter_num != currentfilter_num:\n",
    "                    print('loading rank from: ' + prefix + str(conv_cnt) + subfix)\n",
    "                    rank = np.load(prefix + str(conv_cnt) + subfix)\n",
    "                    select_index = np.argsort(rank)[orifilter_num - currentfilter_num:]  # preserved filter id\n",
    "                    select_index.sort()\n",
    "\n",
    "                    if (l==6 or (l==0 and layer_cnt!=1) or (l==3 and layer_cnt==1)) and last_select_index is not None:\n",
    "                        for index_i, i in enumerate(select_index):\n",
    "                            for index_j, j in enumerate(last_select_index):\n",
    "                                state_dict[name_base+conv_weight_name][index_i][index_j] = \\\n",
    "                                    oristate_dict[conv_weight_name][i][j]\n",
    "                            for bn_part in bn_part_name:\n",
    "                                state_dict[name_base + bn_name + bn_part][index_i] = \\\n",
    "                                    oristate_dict[bn_name + bn_part][i]\n",
    "                    else:\n",
    "                        for index_i, i in enumerate(select_index):\n",
    "                            state_dict[name_base+conv_weight_name][index_i] = \\\n",
    "                                oristate_dict[conv_weight_name][i]\n",
    "                            for bn_part in bn_part_name:\n",
    "                                state_dict[name_base + bn_name + bn_part][index_i] = \\\n",
    "                                    oristate_dict[bn_name + bn_part][i]\n",
    "\n",
    "                    last_select_index = select_index\n",
    "\n",
    "                elif  (l==6 or (l==0 and layer_cnt!=1) or (l==3 and layer_cnt==1)) and last_select_index is not None:\n",
    "                    for index_i in range(orifilter_num):\n",
    "                        for index_j, j in enumerate(last_select_index):\n",
    "                            state_dict[name_base+conv_weight_name][index_i][index_j] = \\\n",
    "                                oristate_dict[conv_weight_name][index_i][j]\n",
    "                    for bn_part in bn_part_name:\n",
    "                        state_dict[name_base + bn_name + bn_part] = \\\n",
    "                            oristate_dict[bn_name + bn_part]\n",
    "                    last_select_index = None\n",
    "\n",
    "                else:\n",
    "                    state_dict[name_base+conv_weight_name] = oriweight\n",
    "                    for bn_part in bn_part_name:\n",
    "                        state_dict[name_base + bn_name + bn_part] = \\\n",
    "                            oristate_dict[bn_name + bn_part]\n",
    "                    last_select_index = None\n",
    "\n",
    "                state_dict[name_base + bn_name + '.num_batches_tracked'] = oristate_dict[bn_name + '.num_batches_tracked']\n",
    "\n",
    "            layer_cnt+=1\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        name = name.replace('module.', '')\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            conv_name = name + '.weight'\n",
    "            bn_name = list(name[:])\n",
    "            bn_name[-1] = str(int(name[-1])+1)\n",
    "            bn_name = ''.join(bn_name)\n",
    "            if conv_name not in all_honey_conv_weight:\n",
    "                state_dict[name_base+conv_name] = oristate_dict[conv_name]\n",
    "                for bn_part in bn_part_name:\n",
    "                    state_dict[name_base + bn_name + bn_part] = \\\n",
    "                        oristate_dict[bn_name + bn_part]\n",
    "                state_dict[name_base + bn_name + '.num_batches_tracked'] = oristate_dict[bn_name + '.num_batches_tracked']\n",
    "\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            state_dict[name_base+name + '.weight'] = oristate_dict[name + '.weight']\n",
    "            state_dict[name_base+name + '.bias'] = oristate_dict[name + '.bias']\n",
    "\n",
    "    model.load_state_dict(state_dict,strict=False)\n",
    "    print(\"finish pruning\")\n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch, step, len_iter):\n",
    "\n",
    "    if lr_type == 'step':\n",
    "        factor = epoch // 30\n",
    "        if epoch >= 80:\n",
    "            factor = factor + 1\n",
    "        lr = learning_rate * (0.1 ** factor)\n",
    "\n",
    "    elif lr_type == 'cos':  # cos without warm-up\n",
    "        lr = 0.5 * learning_rate * (1 + math.cos(math.pi * (epoch - 5) / (epochs - 5)))\n",
    "\n",
    "    elif lr_type == 'exp':\n",
    "        step = 1\n",
    "        decay = 0.96\n",
    "        lr = learning_rate * (decay ** (epoch // step))\n",
    "\n",
    "    elif lr_type == 'fixed':\n",
    "        lr = learning_rate\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    #Warmup\n",
    "    if epoch < 5:\n",
    "        lr = lr * float(1 + step + epoch * len_iter) / (5. * len_iter)\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    if step == 0:\n",
    "        print('learning_rate: ' + str(lr))\n",
    "\n",
    "def load_resnet_model(model, oristate_dict, layer):\n",
    "    cfg = {\n",
    "        56: [9, 9, 9],\n",
    "        110: [18, 18, 18],\n",
    "    }\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    current_cfg = cfg[layer]\n",
    "    last_select_index = None\n",
    "\n",
    "    all_conv_weight = []\n",
    "\n",
    "    prefix = rank_conv_prefix+'rank_conv'\n",
    "    subfix = \".npy\"\n",
    "\n",
    "    cnt=1\n",
    "    for layer, num in enumerate(current_cfg):\n",
    "        layer_name = 'layer' + str(layer + 1) + '.'\n",
    "        for k in range(num):\n",
    "            for l in range(2):\n",
    "\n",
    "                cnt+=1\n",
    "                cov_id=cnt\n",
    "\n",
    "                conv_name = layer_name + str(k) + '.conv' + str(l + 1)\n",
    "                conv_weight_name = conv_name + '.weight'\n",
    "                all_conv_weight.append(conv_weight_name)\n",
    "                oriweight = oristate_dict[conv_weight_name]\n",
    "                curweight =state_dict[name_base+conv_weight_name]\n",
    "                orifilter_num = oriweight.size(0)\n",
    "                currentfilter_num = curweight.size(0)\n",
    "\n",
    "                if orifilter_num != currentfilter_num:\n",
    "                    print('loading rank from: ' + prefix + str(cov_id) + subfix)\n",
    "                    rank = np.load(prefix + str(cov_id) + subfix)\n",
    "                    select_index = np.argsort(rank)[orifilter_num - currentfilter_num:]  # preserved filter id\n",
    "                    select_index.sort()\n",
    "\n",
    "                    if last_select_index is not None:\n",
    "                        for index_i, i in enumerate(select_index):\n",
    "                            for index_j, j in enumerate(last_select_index):\n",
    "                                state_dict[name_base+conv_weight_name][index_i][index_j] = \\\n",
    "                                    oristate_dict[conv_weight_name][i][j]\n",
    "                    else:\n",
    "                        for index_i, i in enumerate(select_index):\n",
    "                            state_dict[name_base+conv_weight_name][index_i] = \\\n",
    "                                oristate_dict[conv_weight_name][i]\n",
    "\n",
    "                    last_select_index = select_index\n",
    "\n",
    "                elif last_select_index is not None:\n",
    "                    for index_i in range(orifilter_num):\n",
    "                        for index_j, j in enumerate(last_select_index):\n",
    "                            state_dict[name_base+conv_weight_name][index_i][index_j] = \\\n",
    "                                oristate_dict[conv_weight_name][index_i][j]\n",
    "                    last_select_index = None\n",
    "\n",
    "                else:\n",
    "                    state_dict[name_base+conv_weight_name] = oriweight\n",
    "                    last_select_index = None\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        name = name.replace('module.', '')\n",
    "\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            conv_name = name + '.weight'\n",
    "            if 'shortcut' in name:\n",
    "                continue\n",
    "            if conv_name not in all_conv_weight:\n",
    "                state_dict[name_base+conv_name] = oristate_dict[conv_name]\n",
    "\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            state_dict[name_base+name + '.weight'] = oristate_dict[name + '.weight']\n",
    "            state_dict[name_base+name + '.bias'] = oristate_dict[name + '.bias']\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "def process_compress_rate(compress_rate):\n",
    "    if compress_rate:# 处理args.compress_rate\n",
    "        import re\n",
    "        cprate_str = compress_rate\n",
    "        cprate_str_list = cprate_str.split('+')\n",
    "        pat_cprate = re.compile(r'\\d+\\.\\d*')\n",
    "        pat_num = re.compile(r'\\*\\d+')\n",
    "        cprate = []\n",
    "        for x in cprate_str_list:\n",
    "            num = 1\n",
    "            find_num = re.findall(pat_num, x)\n",
    "            if find_num:\n",
    "                assert len(find_num) == 1\n",
    "                num = int(find_num[0].replace('*', ''))\n",
    "            find_cprate = re.findall(pat_cprate, x)\n",
    "            assert len(find_cprate) == 1\n",
    "            cprate += [float(find_cprate[0])] * num\n",
    "\n",
    "        compress_rate = cprate\n",
    "        return compress_rate\n",
    "    \n",
    "def load_vgg_model(model, oristate_dict):\n",
    "    state_dict = model.state_dict()\n",
    "    last_select_index = None #Conv index selected in the previous layer\n",
    "\n",
    "    cnt=0\n",
    "    prefix = rank_conv_prefix+'/rank_conv'\n",
    "    subfix = \".npy\"\n",
    "    for name, module in model.named_modules():\n",
    "        name = name.replace('module.', '')\n",
    "\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "\n",
    "            cnt+=1\n",
    "            oriweight = oristate_dict[name + '.weight']\n",
    "            curweight =state_dict[name_base+name + '.weight']\n",
    "            orifilter_num = oriweight.size(0)\n",
    "            currentfilter_num = curweight.size(0)\n",
    "\n",
    "            if orifilter_num != currentfilter_num:\n",
    "\n",
    "                cov_id = cnt\n",
    "                print('loading rank from: ' + prefix + str(cov_id) + subfix)\n",
    "                rank = np.load(prefix + str(cov_id) + subfix)\n",
    "                select_index = np.argsort(rank)[orifilter_num-currentfilter_num:]  # preserved filter id\n",
    "                select_index.sort()\n",
    "\n",
    "                if last_select_index is not None:\n",
    "                    for index_i, i in enumerate(select_index):\n",
    "                        for index_j, j in enumerate(last_select_index):\n",
    "                            state_dict[name_base+name + '.weight'][index_i][index_j] = \\\n",
    "                                oristate_dict[name + '.weight'][i][j]\n",
    "                else:\n",
    "                    for index_i, i in enumerate(select_index):\n",
    "                       state_dict[name_base+name + '.weight'][index_i] = \\\n",
    "                            oristate_dict[name + '.weight'][i]\n",
    "\n",
    "                last_select_index = select_index\n",
    "\n",
    "            elif last_select_index is not None:\n",
    "                for i in range(orifilter_num):\n",
    "                    for index_j, j in enumerate(last_select_index):\n",
    "                        state_dict[name_base+name + '.weight'][i][index_j] = \\\n",
    "                            oristate_dict[name + '.weight'][i][j]\n",
    "            else:\n",
    "                state_dict[name_base+name + '.weight'] = oriweight\n",
    "                last_select_index = None\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "def load_densenet_model(model, oristate_dict):\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "    last_select_index = [] #Conv index selected in the previous layer\n",
    "\n",
    "    cnt=0\n",
    "    prefix = rank_conv_prefix+'/rank_conv'\n",
    "    subfix = \".npy\"\n",
    "    for name, module in model.named_modules():\n",
    "        name = name.replace('module.', '')\n",
    "\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "\n",
    "            cnt+=1\n",
    "            cov_id = cnt\n",
    "            oriweight = oristate_dict[name + '.weight']\n",
    "            curweight = state_dict[name_base+name + '.weight']\n",
    "            orifilter_num = oriweight.size(0)\n",
    "            currentfilter_num = curweight.size(0)\n",
    "\n",
    "            if orifilter_num != currentfilter_num:\n",
    "                logger.info('loading rank from: ' + prefix + str(cov_id) + subfix)\n",
    "                rank = np.load(prefix + str(cov_id) + subfix)\n",
    "                select_index = list(np.argsort(rank)[orifilter_num-currentfilter_num:])  # preserved filter id\n",
    "                select_index.sort()\n",
    "\n",
    "                if last_select_index is not None:\n",
    "                    for index_i, i in enumerate(select_index):\n",
    "                        for index_j, j in enumerate(last_select_index):\n",
    "                            state_dict[name_base+name + '.weight'][index_i][index_j] = \\\n",
    "                                oristate_dict[name + '.weight'][i][j]\n",
    "                else:\n",
    "                    for index_i, i in enumerate(select_index):\n",
    "                        state_dict[name_base+name + '.weight'][index_i] = \\\n",
    "                            oristate_dict[name + '.weight'][i]\n",
    "\n",
    "            elif last_select_index is not None:\n",
    "                for i in range(orifilter_num):\n",
    "                    for index_j, j in enumerate(last_select_index):\n",
    "                        state_dict[name_base+name + '.weight'][i][index_j] = \\\n",
    "                            oristate_dict[name + '.weight'][i][j]\n",
    "                select_index = list(range(0, orifilter_num))\n",
    "\n",
    "            else:\n",
    "                select_index = list(range(0, orifilter_num))\n",
    "                state_dict[name_base+name + '.weight'] = oriweight\n",
    "\n",
    "            if cov_id==1 or cov_id==14 or cov_id==27:\n",
    "                last_select_index = select_index\n",
    "            else:\n",
    "                tmp_select_index = [x+cov_id*12-(cov_id-1)//13*12 for x in select_index]\n",
    "                last_select_index += tmp_select_index\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:41:31.531855Z",
     "start_time": "2020-11-04T01:41:31.500823Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled=True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:21:56.041327Z",
     "start_time": "2020-11-04T02:21:56.037324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超参数\n",
      "PruneGraft_teaLevel_press2_mobilenet_v2\n"
     ]
    }
   ],
   "source": [
    "print(\"超参数\")\n",
    "CLASSES = 9\n",
    "lr_type = 'step'\n",
    "epochs = 300\n",
    "batch_size=  128\n",
    "no_graft = False\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "# 0.006\n",
    "weight_decay = 0.005\n",
    "label_smooth = 0.1 \n",
    "lr_decay_step = '150,225'\n",
    "\n",
    "best_acc = 0\n",
    "# \"mobilenet_v2\" \"resnet_56\" \"vgg\"\n",
    "arch = \"mobilenet_v2\"\n",
    "# \"[0.]+[0.4]*2+[0.5]*9+[0.6]*9+[0.7]*9\" “[0.]+[0.15]*2+[0.4]*27”\"'[0.]+[0.18]*29'\"\n",
    "# \"[0.21]*7+[0.75]*5\" \"[0.45]*7+[0.75]*5\"\n",
    "#[0.]+[0.2]*2+[0.3]*18+[0.35]*36\n",
    "compress_rate = \"[0.]+[0.3]*7\"\n",
    "# \"./data/model/Hrank_preTrain/cifar-10/resnet_56.pt.pt\"\n",
    "pretrain_dir = \"./data/model/Hrank_preTrain/teaLevel/mobilenetV2-92-901.t7\"\n",
    "save_dir = \"PruneGraft_teaLevel_press2_\"+arch\n",
    "data_dir = \"./data/teaLevel/singleLeaf/\"\n",
    "rank_conv_dir = \"./data/model/rank_conv/teaLevel/mobileNetV2_limit5/\"\n",
    "print(save_dir)\n",
    "\n",
    "muti_net = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:21:56.399660Z",
     "start_time": "2020-11-04T02:21:56.396658Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare compress_rate\n",
      "compress_rate:[0.0, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "print(\"prepare compress_rate\")\n",
    "compress_rate = process_compress_rate(compress_rate)\n",
    "print('compress_rate:' + str(compress_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:24:09.742863Z",
     "start_time": "2020-11-04T02:24:09.610741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_bn() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.ModuleList'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class 'torch.nn.modules.container.Sequential'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.BasicBlock'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.LambdaLayer'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "\u001b[91m[WARN] Cannot find rule for <class '__main__.ResNet'>. Treat it as zero Macs and zero Params.\u001b[00m\n",
      "Params: 1727897.00\n",
      "Flops: 4079813248.00\n"
     ]
    }
   ],
   "source": [
    "net_1 = resnet_110(compress_rate=[0.] * 100,num_classes=9).cuda()\n",
    "\n",
    "input_image_size=128\n",
    "input_image = torch.randn(1, 3, input_image_size, input_image_size).cuda()\n",
    "flops, params = profile(net_1, inputs=(input_image,))\n",
    "print('Params: %.2f' % (params))\n",
    "print('Flops: %.2f' % (flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T14:15:54.638358Z",
     "start_time": "2020-11-02T14:14:53.023866Z"
    },
    "code_folding": [
     1,
     23,
     43,
     61,
     77
    ]
   },
   "outputs": [],
   "source": [
    "print(\"=====> Building model\")\n",
    "if arch == \"mobilenet_v2\":\n",
    "    net_1 = mobilenet_v2(compress_rate,n_class=CLASSES)\n",
    "    net_2 = mobilenet_v2(compress_rate,n_class=CLASSES)\n",
    "    net_1.to(device)\n",
    "    net_2.to(device)\n",
    "\n",
    "    rank_conv_prefix = rank_conv_dir\n",
    "    name_base=''\n",
    "\n",
    "    origin_model = mobilenet_v2(compress_rate=[0.] * 100,n_class=CLASSES).cuda()\n",
    "    ckpt = torch.load(pretrain_dir)\n",
    "    # ckpt = {k:v for k,v in ckpt.items() if \"classifier\" not in k}\n",
    "    ckpt = ckpt[\"net\"]\n",
    "\n",
    "    origin_model.load_state_dict(ckpt)\n",
    "    oristate_dict = origin_model.state_dict()\n",
    "    load_mobilenetv2_model(net_1,oristate_dict)\n",
    "    load_mobilenetv2_model(net_2,oristate_dict)\n",
    "    \n",
    "    if muti_net:\n",
    "        net_3 = mobilenet_v2(compress_rate,n_class=CLASSES).to(device)\n",
    "        load_mobilenetv2_model(net_3,oristate_dict)\n",
    "if arch == \"resnet_56\":\n",
    "    net_1 = resnet_56(compress_rate,CLASSES)\n",
    "    net_2 = resnet_56(compress_rate,CLASSES)\n",
    "    net_1.to(device)\n",
    "    net_2.to(device)\n",
    "    rank_conv_prefix = rank_conv_dir\n",
    "    name_base=''\n",
    "    \n",
    "    origin_model = resnet_56(compress_rate=[0.] * 100,num_classes=CLASSES).cuda()\n",
    "    ckpt = torch.load(pretrain_dir, map_location='cuda:0')\n",
    "    ckpt = ckpt[\"net\"]\n",
    "    origin_model.load_state_dict(ckpt)\n",
    "    \n",
    "    oristate_dict = origin_model.state_dict()\n",
    "    load_resnet_model(net_1, oristate_dict, 56)\n",
    "    print(\"-------------------\")\n",
    "    load_resnet_model(net_2, oristate_dict, 56)\n",
    "    if muti_net:\n",
    "        net_3 = resnet_56(compress_rate,CLASSES).to(device)\n",
    "        load_resnet_model(net_3,oristate_dict,56)\n",
    "if arch == \"resnet_110\":\n",
    "    net_1 = resnet_56(compress_rate,CLASSES)\n",
    "    net_2 = resnet_56(compress_rate,CLASSES)\n",
    "    net_1.to(device)\n",
    "    net_2.to(device)\n",
    "    rank_conv_prefix = rank_conv_dir\n",
    "    name_base=''\n",
    "    origin_model = resnet_110(compress_rate=[0.] * 100,num_classes=CLASSES).cuda()\n",
    "    ckpt = torch.load(pretrain_dir, map_location='cuda:0')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in ckpt['net'].items():\n",
    "        new_state_dict[k.replace('module.', '')] = v\n",
    "    origin_model.load_state_dict(new_state_dict)\n",
    "    \n",
    "    oristate_dict = origin_model.state_dict()\n",
    "    load_resnet_model(net_1, oristate_dict, 110)\n",
    "    print(\"-------------------\")\n",
    "    load_resnet_model(net_2, oristate_dict, 110)\n",
    "if arch == \"vgg\":\n",
    "    net_1 = vgg_16_bn(compress_rate)\n",
    "    net_2 = vgg_16_bn(compress_rate)\n",
    "    net_1.to(device)\n",
    "    net_2.to(device)\n",
    "    rank_conv_prefix = rank_conv_dir\n",
    "    name_base=''\n",
    "    \n",
    "    origin_model = vgg_16_bn(compress_rate=[0.] * 100).cuda()\n",
    "    ckpt = torch.load(pretrain_dir, map_location='cuda:0')\n",
    "    ckpt = ckpt[\"net\"]\n",
    "    origin_model.load_state_dict(ckpt)\n",
    "    oristate_dict = origin_model.state_dict()\n",
    "    \n",
    "    load_vgg_model(net_1,oristate_dict)\n",
    "    load_vgg_model(net_2,oristate_dict)\n",
    "if arch == \"densnet_40\":\n",
    "    net_1 = densenet_40(compress_rate=[0.] * 100)\n",
    "    net_2 = densenet_40(compress_rate=[0.] * 100)\n",
    "    net_1.to(device)\n",
    "    net_2.to(device)\n",
    "    rank_conv_prefix = rank_conv_dir\n",
    "    name_base=''\n",
    "    \n",
    "    origin_model = densenet_40(compress_rate=[0.] * 100).cuda()\n",
    "    ckpt = torch.load(pretrain_dir, map_location='cuda:0')\n",
    "    ckpt = ckpt[\"net\"]\n",
    "    origin_model.load_state_dict(ckpt)\n",
    "    \n",
    "    load_densenet_model(net_1, oristate_dict)\n",
    "    load_densenet_model(net_2, oristate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T14:15:54.648368Z",
     "start_time": "2020-11-02T14:15:54.638358Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "\n",
    "  def __init__(self, num_classes, epsilon):\n",
    "    super(CrossEntropyLabelSmooth, self).__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.epsilon = epsilon\n",
    "    self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, inputs, targets):\n",
    "    log_probs = self.logsoftmax(inputs)\n",
    "    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "    loss = (-targets * log_probs).mean(0).sum()\n",
    "    return loss   \n",
    "\n",
    "\n",
    "criterion_1 = nn.CrossEntropyLoss()\n",
    "criterion_1 = criterion_1.cuda()\n",
    "criterion_smooth_1 = CrossEntropyLabelSmooth(CLASSES, 0.1)\n",
    "criterion_smooth_1 = criterion_smooth_1.cuda()\n",
    "\n",
    "criterion_2 = nn.CrossEntropyLoss()\n",
    "criterion_2 = criterion_2.cuda()\n",
    "criterion_smooth_2 = CrossEntropyLabelSmooth(CLASSES, 0.1)\n",
    "criterion_smooth_2 = criterion_smooth_2.cuda()\n",
    "\n",
    "optimizer_1 = torch.optim.SGD(net_1.parameters(), learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "optimizer_2 = torch.optim.SGD(net_2.parameters(), 0.001, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_decay_step = list(map(int, lr_decay_step.split(',')))\n",
    "scheduler_1 = torch.optim.lr_scheduler.MultiStepLR(optimizer_1, milestones=lr_decay_step, gamma=0.1)\n",
    "scheduler_2 = torch.optim.lr_scheduler.MultiStepLR(optimizer_2, milestones=lr_decay_step, gamma=0.1)\n",
    "\n",
    "lr_scheduler_1 = torch.optim.lr_scheduler.StepLR(optimizer_1, step_size=60, gamma=0.1)\n",
    "lr_scheduler_2 = torch.optim.lr_scheduler.StepLR(optimizer_2, step_size=60, gamma=0.1)\n",
    "\n",
    "if muti_net:\n",
    "    criterion_3 = nn.CrossEntropyLoss()\n",
    "    criterion_3 = criterion_1.cuda()\n",
    "    criterion_smooth_3 = CrossEntropyLabelSmooth(CLASSES, 0.1)\n",
    "    criterion_smooth_3 = criterion_smooth_1.cuda()\n",
    "    optimizer_3 = torch.optim.SGD(net_3.parameters(), 0.2, momentum=momentum, weight_decay=0.0006)\n",
    "    scheduler_3 = torch.optim.lr_scheduler.MultiStepLR(optimizer_3, milestones=lr_decay_step, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T14:15:54.701418Z",
     "start_time": "2020-11-02T14:15:54.649369Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if not no_graft:\n",
    "    for epoch in range(300):\n",
    "        scheduler_1.step()\n",
    " #       scheduler_2.step()\n",
    "        if muti_net: scheduler_3.step()\n",
    "    ck1 = torch.load(\"./data/model/PruneGraft_teaLevel_press2_mobilenet_v2/moblie-92.t7\")\n",
    " #   ck2 = torch.load(\"./data/model/PruneGraft_teaLevel_press1_vgg/vgg-nograft-92-284.t7\")\n",
    "    net_1.load_state_dict(ck1[\"net\"])\n",
    "#    net_2.load_state_dict(ck2[\"net\"])\n",
    "    if muti_net: net_3.load_state_dict(ck[\"net\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T14:15:54.729444Z",
     "start_time": "2020-11-02T14:15:54.705422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load training data\n"
     ]
    }
   ],
   "source": [
    "print('load training data')\n",
    "data_transform = {\n",
    "    \"train\": transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]),\n",
    "    \"val\": transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=data_dir+\"train\",transform=data_transform[\"train\"])\n",
    "train_num = len(train_dataset)\n",
    "\n",
    "tea_list = train_dataset.class_to_idx\n",
    "cla_dict = dict((val, key) for key, val in tea_list.items())\n",
    "json_str = json.dumps(cla_dict, indent=4)\n",
    "with open('class_indices.json', 'w') as json_file:\n",
    "    json_file.write(json_str)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "validate_dataset = datasets.ImageFolder(root=data_dir + \"val\",transform=data_transform[\"val\"])\n",
    "val_num = len(validate_dataset)\n",
    "testloader = torch.utils.data.DataLoader(validate_dataset,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T14:15:54.748462Z",
     "start_time": "2020-11-02T14:15:54.730446Z"
    },
    "code_folding": [
     0,
     9,
     14,
     20,
     34,
     61,
     86
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def entropy(x, n=10):\n",
    "    x = x.reshape(-1)\n",
    "    scale = (x.max() - x.min()) / n\n",
    "    entropy = 0\n",
    "    for i in range(n):\n",
    "        p = torch.sum((x >= x.min() + i * scale) * (x < x.min() + (i + 1) * scale), dtype=torch.float) / len(x)\n",
    "        if p != 0:\n",
    "            entropy -= p * torch.log(p)\n",
    "    return float(entropy.cpu())\n",
    "def l2_norm(weight_torch):\n",
    "    weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n",
    "    norm = torch.norm(weight_vec, 2, 1)\n",
    "    norm_np = norm.cpu().numpy()\n",
    "    return sum(norm_np)\n",
    "def Geometric_dist(weight_torch,n=2):\n",
    "    weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n",
    "    weight_vec = weight_vec.cpu().numpy()\n",
    "    similar_matrix = distance.cdist(weight_vec, weight_vec, 'euclidean')\n",
    "    similar_sum = np.sum(np.abs(similar_matrix), axis=0)\n",
    "    return similar_sum[similar_large_index]-similar_sum[similar_small_index]\n",
    "def disEn(weight_torch):\n",
    "        weight_vec = weight_torch.view(weight_torch.size()[0],-1)\n",
    "        weight_vec = weight_vec.cpu().numpy()\n",
    "        similar_matrix = distance.cdist(weight_vec, weight_vec, 'euclidean')\n",
    "        similar_sum = np.sum(np.abs(similar_matrix), axis=0)\n",
    "        x = torch.Tensor(similar_sum).cuda()\n",
    "        n = 5\n",
    "        scale = (x.max() - x.min()) / n\n",
    "        entropy = 0\n",
    "        for i in range(n):\n",
    "            p = torch.sum((x >= x.min() + i * scale) * (x < x.min() + (i + 1) * scale), dtype=torch.float) / len(x)\n",
    "            if p != 0:\n",
    "                entropy -= p * torch.log(p)\n",
    "        return float(entropy.cpu())\n",
    "def train(epoch,i,net,optimizer,scheduler,criterion):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    num_iter = len(trainloader)\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "#         adjust_learning_rate(optimizer, epoch, batch_idx, num_iter)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        if batch_idx % 1000 == 1000 - 1 or 1000 == trainloader.__len__() - 1:\n",
    "            print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "                train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "    scheduler.step()  \n",
    "def test(epoch,net,i,criterion):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100. * correct / total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc\n",
    "        }\n",
    "        torch.save(state, './data/model/'+save_dir+'/best_%d.t7' % (epoch))\n",
    "    print('Network:%d    epoch:%d    accuracy:%.3f    best:%.3f' % (i, epoch, acc, best_acc))\n",
    "def grafting(net, epoch,i):\n",
    "    while True:\n",
    "        try:\n",
    "            checkpoint = torch.load('./data/model/'+save_dir+'/ckpt%d_%d.t7' % (i - 1, epoch))['net']\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    model = collections.OrderedDict()\n",
    "    w = 1 \n",
    "    for i, (key, u) in enumerate(net.state_dict().items()):\n",
    "        if 'conv' in key and 'weight' in key:\n",
    "            w = round(0.4 / np.pi * np.arctan(500 * (disEn(u) - disEn(checkpoint[key]))) + 0.5, 2)\n",
    "        model[key] = u * w + checkpoint[key] * (1 - w)\n",
    "        \n",
    "    net.load_state_dict(model)\n",
    "    \n",
    "# for epoch in range(200):\n",
    "#     scheduler_1.step()\n",
    "#     scheduler_2.step()\n",
    "if muti_net: num = 3\n",
    "else: num = 2\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:26:16.611136Z",
     "start_time": "2020-11-02T14:15:54.749463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:0    accuracy:91.667    best:91.667\n",
      "Network:2    epoch:0    accuracy:30.556    best:91.667\n",
      "Network:1    epoch:1    accuracy:29.630    best:91.667\n",
      "Network:2    epoch:1    accuracy:39.198    best:91.667\n",
      "Network:1    epoch:2    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:2    accuracy:68.210    best:91.667\n",
      "Network:1    epoch:3    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:3    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:4    accuracy:83.642    best:91.667\n",
      "Network:2    epoch:4    accuracy:80.864    best:91.667\n",
      "Network:1    epoch:5    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:5    accuracy:79.321    best:91.667\n",
      "Network:1    epoch:6    accuracy:72.222    best:91.667\n",
      "Network:2    epoch:6    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:7    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:7    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:8    accuracy:72.840    best:91.667\n",
      "Network:2    epoch:8    accuracy:79.938    best:91.667\n",
      "Network:1    epoch:9    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:9    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:10    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:10    accuracy:72.222    best:91.667\n",
      "Network:1    epoch:11    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:11    accuracy:79.321    best:91.667\n",
      "Network:1    epoch:12    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:12    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:13    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:13    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:14    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:14    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:15    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:15    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:16    accuracy:75.309    best:91.667\n",
      "Network:2    epoch:16    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:17    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:17    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:18    accuracy:74.383    best:91.667\n",
      "Network:2    epoch:18    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:19    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:19    accuracy:85.802    best:91.667\n",
      "Network:1    epoch:20    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:20    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:21    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:21    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:22    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:22    accuracy:81.790    best:91.667\n",
      "Network:1    epoch:23    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:23    accuracy:83.951    best:91.667\n",
      "Network:1    epoch:24    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:24    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:25    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:25    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:26    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:26    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:27    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:27    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:28    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:28    accuracy:84.259    best:91.667\n",
      "Network:1    epoch:29    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:29    accuracy:86.111    best:91.667\n",
      "Network:1    epoch:30    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:30    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:31    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:31    accuracy:82.716    best:91.667\n",
      "Network:1    epoch:32    accuracy:76.852    best:91.667\n",
      "Network:2    epoch:32    accuracy:75.926    best:91.667\n",
      "Network:1    epoch:33    accuracy:75.000    best:91.667\n",
      "Network:2    epoch:33    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:34    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:34    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:35    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:35    accuracy:85.802    best:91.667\n",
      "Network:1    epoch:36    accuracy:73.765    best:91.667\n",
      "Network:2    epoch:36    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:37    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:37    accuracy:85.185    best:91.667\n",
      "Network:1    epoch:38    accuracy:67.901    best:91.667\n",
      "Network:2    epoch:38    accuracy:85.185    best:91.667\n",
      "Network:1    epoch:39    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:39    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:40    accuracy:72.222    best:91.667\n",
      "Network:2    epoch:40    accuracy:78.086    best:91.667\n",
      "Network:1    epoch:41    accuracy:73.765    best:91.667\n",
      "Network:2    epoch:41    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:42    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:42    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:43    accuracy:73.148    best:91.667\n",
      "Network:2    epoch:43    accuracy:82.407    best:91.667\n",
      "Network:1    epoch:44    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:44    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:45    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:45    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:46    accuracy:75.926    best:91.667\n",
      "Network:2    epoch:46    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:47    accuracy:71.914    best:91.667\n",
      "Network:2    epoch:47    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:48    accuracy:73.148    best:91.667\n",
      "Network:2    epoch:48    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:49    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:49    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:50    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:50    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:51    accuracy:74.691    best:91.667\n",
      "Network:2    epoch:51    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:52    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:52    accuracy:85.802    best:91.667\n",
      "Network:1    epoch:53    accuracy:73.765    best:91.667\n",
      "Network:2    epoch:53    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:54    accuracy:73.457    best:91.667\n",
      "Network:2    epoch:54    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:55    accuracy:70.062    best:91.667\n",
      "Network:2    epoch:55    accuracy:83.333    best:91.667\n",
      "Network:1    epoch:56    accuracy:70.988    best:91.667\n",
      "Network:2    epoch:56    accuracy:79.321    best:91.667\n",
      "Network:1    epoch:57    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:57    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:58    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:58    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:59    accuracy:77.469    best:91.667\n",
      "Network:2    epoch:59    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:60    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:60    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:61    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:61    accuracy:84.259    best:91.667\n",
      "Network:1    epoch:62    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:62    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:63    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:63    accuracy:85.802    best:91.667\n",
      "Network:1    epoch:64    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:64    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:65    accuracy:71.605    best:91.667\n",
      "Network:2    epoch:65    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:66    accuracy:73.457    best:91.667\n",
      "Network:2    epoch:66    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:67    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:67    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:68    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:68    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:69    accuracy:82.407    best:91.667\n",
      "Network:2    epoch:69    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:70    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:70    accuracy:83.025    best:91.667\n",
      "Network:1    epoch:71    accuracy:77.469    best:91.667\n",
      "Network:2    epoch:71    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:72    accuracy:75.926    best:91.667\n",
      "Network:2    epoch:72    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:73    accuracy:75.926    best:91.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:2    epoch:73    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:74    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:74    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:75    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:75    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:76    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:76    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:77    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:77    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:78    accuracy:73.457    best:91.667\n",
      "Network:2    epoch:78    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:79    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:79    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:80    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:80    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:81    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:81    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:82    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:82    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:83    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:83    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:84    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:84    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:85    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:85    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:86    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:86    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:87    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:87    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:88    accuracy:75.000    best:91.667\n",
      "Network:2    epoch:88    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:89    accuracy:77.469    best:91.667\n",
      "Network:2    epoch:89    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:90    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:90    accuracy:83.951    best:91.667\n",
      "Network:1    epoch:91    accuracy:83.025    best:91.667\n",
      "Network:2    epoch:91    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:92    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:92    accuracy:85.185    best:91.667\n",
      "Network:1    epoch:93    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:93    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:94    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:94    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:95    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:95    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:96    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:96    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:97    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:97    accuracy:86.111    best:91.667\n",
      "Network:1    epoch:98    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:98    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:99    accuracy:77.160    best:91.667\n",
      "Network:2    epoch:99    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:100    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:100    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:101    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:101    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:102    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:102    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:103    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:103    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:104    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:104    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:105    accuracy:83.333    best:91.667\n",
      "Network:2    epoch:105    accuracy:86.111    best:91.667\n",
      "Network:1    epoch:106    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:106    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:107    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:107    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:108    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:108    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:109    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:109    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:110    accuracy:75.309    best:91.667\n",
      "Network:2    epoch:110    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:111    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:111    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:112    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:112    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:113    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:113    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:114    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:114    accuracy:86.111    best:91.667\n",
      "Network:1    epoch:115    accuracy:74.074    best:91.667\n",
      "Network:2    epoch:115    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:116    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:116    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:117    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:117    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:118    accuracy:82.407    best:91.667\n",
      "Network:2    epoch:118    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:119    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:119    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:120    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:120    accuracy:84.259    best:91.667\n",
      "Network:1    epoch:121    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:121    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:122    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:122    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:123    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:123    accuracy:73.765    best:91.667\n",
      "Network:1    epoch:124    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:124    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:125    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:125    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:126    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:126    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:127    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:127    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:128    accuracy:82.407    best:91.667\n",
      "Network:2    epoch:128    accuracy:83.951    best:91.667\n",
      "Network:1    epoch:129    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:129    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:130    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:130    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:131    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:131    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:132    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:132    accuracy:83.025    best:91.667\n",
      "Network:1    epoch:133    accuracy:70.370    best:91.667\n",
      "Network:2    epoch:133    accuracy:85.494    best:91.667\n",
      "Network:1    epoch:134    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:134    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:135    accuracy:84.259    best:91.667\n",
      "Network:2    epoch:135    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:136    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:136    accuracy:87.037    best:91.667\n",
      "Network:1    epoch:137    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:137    accuracy:86.728    best:91.667\n",
      "Network:1    epoch:138    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:138    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:139    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:139    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:140    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:140    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:141    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:141    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:142    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:142    accuracy:85.185    best:91.667\n",
      "Network:1    epoch:143    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:143    accuracy:84.877    best:91.667\n",
      "Network:1    epoch:144    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:144    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:145    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:145    accuracy:88.889    best:91.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:146    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:146    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:147    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:147    accuracy:81.790    best:91.667\n",
      "Network:1    epoch:148    accuracy:75.926    best:91.667\n",
      "Network:2    epoch:148    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:149    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:149    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:150    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:150    accuracy:91.049    best:91.667\n",
      "Network:1    epoch:151    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:151    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:152    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:152    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:153    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:153    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:154    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:154    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:155    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:155    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:156    accuracy:76.852    best:91.667\n",
      "Network:2    epoch:156    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:157    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:157    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:158    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:158    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:159    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:159    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:160    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:160    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:161    accuracy:74.691    best:91.667\n",
      "Network:2    epoch:161    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:162    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:162    accuracy:91.049    best:91.667\n",
      "Network:1    epoch:163    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:163    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:164    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:164    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:165    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:165    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:166    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:166    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:167    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:167    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:168    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:168    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:169    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:169    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:170    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:170    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:171    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:171    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:172    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:172    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:173    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:173    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:174    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:174    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:175    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:175    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:176    accuracy:77.469    best:91.667\n",
      "Network:2    epoch:176    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:177    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:177    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:178    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:178    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:179    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:179    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:180    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:180    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:181    accuracy:82.716    best:91.667\n",
      "Network:2    epoch:181    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:182    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:182    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:183    accuracy:76.852    best:91.667\n",
      "Network:2    epoch:183    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:184    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:184    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:185    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:185    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:186    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:186    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:187    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:187    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:188    accuracy:75.309    best:91.667\n",
      "Network:2    epoch:188    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:189    accuracy:83.333    best:91.667\n",
      "Network:2    epoch:189    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:190    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:190    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:191    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:191    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:192    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:192    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:193    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:193    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:194    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:194    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:195    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:195    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:196    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:196    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:197    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:197    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:198    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:198    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:199    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:199    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:200    accuracy:76.543    best:91.667\n",
      "Network:2    epoch:200    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:201    accuracy:77.778    best:91.667\n",
      "Network:2    epoch:201    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:202    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:202    accuracy:86.420    best:91.667\n",
      "Network:1    epoch:203    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:203    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:204    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:204    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:205    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:205    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:206    accuracy:76.852    best:91.667\n",
      "Network:2    epoch:206    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:207    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:207    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:208    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:208    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:209    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:209    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:210    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:210    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:211    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:211    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:212    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:212    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:213    accuracy:77.469    best:91.667\n",
      "Network:2    epoch:213    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:214    accuracy:82.716    best:91.667\n",
      "Network:2    epoch:214    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:215    accuracy:78.086    best:91.667\n",
      "Network:2    epoch:215    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:216    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:216    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:217    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:217    accuracy:89.815    best:91.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:218    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:218    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:219    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:219    accuracy:87.346    best:91.667\n",
      "Network:1    epoch:220    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:220    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:221    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:221    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:222    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:222    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:223    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:223    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:224    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:224    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:225    accuracy:71.914    best:91.667\n",
      "Network:2    epoch:225    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:226    accuracy:85.185    best:91.667\n",
      "Network:2    epoch:226    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:227    accuracy:83.951    best:91.667\n",
      "Network:2    epoch:227    accuracy:91.358    best:91.667\n",
      "Network:1    epoch:228    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:228    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:229    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:229    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:230    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:230    accuracy:91.358    best:91.667\n",
      "Network:1    epoch:231    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:231    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:232    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:232    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:233    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:233    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:234    accuracy:83.025    best:91.667\n",
      "Network:2    epoch:234    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:235    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:235    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:236    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:236    accuracy:91.049    best:91.667\n",
      "Network:1    epoch:237    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:237    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:238    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:238    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:239    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:239    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:240    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:240    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:241    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:241    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:242    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:242    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:243    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:243    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:244    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:244    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:245    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:245    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:246    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:246    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:247    accuracy:82.407    best:91.667\n",
      "Network:2    epoch:247    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:248    accuracy:74.383    best:91.667\n",
      "Network:2    epoch:248    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:249    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:249    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:250    accuracy:83.025    best:91.667\n",
      "Network:2    epoch:250    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:251    accuracy:82.716    best:91.667\n",
      "Network:2    epoch:251    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:252    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:252    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:253    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:253    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:254    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:254    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:255    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:255    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:256    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:256    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:257    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:257    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:258    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:258    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:259    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:259    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:260    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:260    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:261    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:261    accuracy:90.741    best:91.667\n",
      "Network:1    epoch:262    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:262    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:263    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:263    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:264    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:264    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:265    accuracy:82.407    best:91.667\n",
      "Network:2    epoch:265    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:266    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:266    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:267    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:267    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:268    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:268    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:269    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:269    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:270    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:270    accuracy:89.815    best:91.667\n",
      "Network:1    epoch:271    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:271    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:272    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:272    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:273    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:273    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:274    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:274    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:275    accuracy:80.247    best:91.667\n",
      "Network:2    epoch:275    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:276    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:276    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:277    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:277    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:278    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:278    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:279    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:279    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:280    accuracy:81.481    best:91.667\n",
      "Network:2    epoch:280    accuracy:87.654    best:91.667\n",
      "Network:1    epoch:281    accuracy:81.790    best:91.667\n",
      "Network:2    epoch:281    accuracy:88.272    best:91.667\n",
      "Network:1    epoch:282    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:282    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:283    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:283    accuracy:90.123    best:91.667\n",
      "Network:1    epoch:284    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:284    accuracy:90.432    best:91.667\n",
      "Network:1    epoch:285    accuracy:80.556    best:91.667\n",
      "Network:2    epoch:285    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:286    accuracy:79.012    best:91.667\n",
      "Network:2    epoch:286    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:287    accuracy:76.235    best:91.667\n",
      "Network:2    epoch:287    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:288    accuracy:78.704    best:91.667\n",
      "Network:2    epoch:288    accuracy:88.889    best:91.667\n",
      "Network:1    epoch:289    accuracy:78.395    best:91.667\n",
      "Network:2    epoch:289    accuracy:87.963    best:91.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network:1    epoch:290    accuracy:79.938    best:91.667\n",
      "Network:2    epoch:290    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:291    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:291    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:292    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:292    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:293    accuracy:79.630    best:91.667\n",
      "Network:2    epoch:293    accuracy:89.198    best:91.667\n",
      "Network:1    epoch:294    accuracy:75.617    best:91.667\n",
      "Network:2    epoch:294    accuracy:91.667    best:91.667\n",
      "Network:1    epoch:295    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:295    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:296    accuracy:81.173    best:91.667\n",
      "Network:2    epoch:296    accuracy:87.963    best:91.667\n",
      "Network:1    epoch:297    accuracy:80.864    best:91.667\n",
      "Network:2    epoch:297    accuracy:88.580    best:91.667\n",
      "Network:1    epoch:298    accuracy:82.099    best:91.667\n",
      "Network:2    epoch:298    accuracy:89.506    best:91.667\n",
      "Network:1    epoch:299    accuracy:79.321    best:91.667\n",
      "Network:2    epoch:299    accuracy:89.506    best:91.667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if  no_graft:\n",
    "    for epoch in range(300):\n",
    "        train(epoch,1,net_1,optimizer_1,scheduler_1,criterion_smooth_1)\n",
    "        test(epoch,net_1,1,criterion_1)\n",
    "        state = {\n",
    "            'net': net_1.state_dict(),\n",
    "        }\n",
    "        torch.save(state, './data/model/'+save_dir+'/ckpt%d_%d.t7' % ( 1%num, epoch))\n",
    "else:\n",
    "    for epoch in range(300):\n",
    "        train(epoch,1,net_1,optimizer_1,scheduler_1,criterion_smooth_1)\n",
    "        test(epoch,net_1,1,criterion_1)\n",
    "        state = {\n",
    "            'net': net_1.state_dict(),\n",
    "        }\n",
    "        torch.save(state, './data/model/'+save_dir+'/ckpt%d_%d.t7' % ( 1%num, epoch))\n",
    "\n",
    "        train(epoch,2,net_2,optimizer_2,scheduler_2,criterion_smooth_2)\n",
    "        test(epoch,net_2,2,criterion_2)\n",
    "        state = {\n",
    "            'net': net_2.state_dict(),\n",
    "\n",
    "        }\n",
    "        torch.save(state, './data/model/'+save_dir+'/ckpt%d_%d.t7' % ( 2%num, epoch))\n",
    "        if muti_net:\n",
    "            train(epoch,3,net_3,optimizer_3,scheduler_3,criterion_smooth_3)\n",
    "            test(epoch,net_3,3,criterion_3)\n",
    "            state = {\n",
    "                'net': net_3.state_dict(),\n",
    "\n",
    "            }\n",
    "            torch.save(state, './data/model/'+save_dir+'/ckpt%d_%d.t7' % ( 300%num, epoch))\n",
    "            grafting(net_3,epoch,3)\n",
    "        grafting(net_1,epoch,1)\n",
    "        grafting(net_2,epoch,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T15:26:16.615140Z",
     "start_time": "2020-11-02T15:26:16.612137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['features.0.0.weight', 'features.0.1.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.running_var', 'features.0.1.num_batches_tracked', 'features.1.conv.0.weight', 'features.1.conv.1.weight', 'features.1.conv.1.bias', 'features.1.conv.1.running_mean', 'features.1.conv.1.running_var', 'features.1.conv.1.num_batches_tracked', 'features.1.conv.3.weight', 'features.1.conv.4.weight', 'features.1.conv.4.bias', 'features.1.conv.4.running_mean', 'features.1.conv.4.running_var', 'features.1.conv.4.num_batches_tracked', 'features.2.conv.0.weight', 'features.2.conv.1.weight', 'features.2.conv.1.bias', 'features.2.conv.1.running_mean', 'features.2.conv.1.running_var', 'features.2.conv.1.num_batches_tracked', 'features.2.conv.3.weight', 'features.2.conv.4.weight', 'features.2.conv.4.bias', 'features.2.conv.4.running_mean', 'features.2.conv.4.running_var', 'features.2.conv.4.num_batches_tracked', 'features.2.conv.6.weight', 'features.2.conv.7.weight', 'features.2.conv.7.bias', 'features.2.conv.7.running_mean', 'features.2.conv.7.running_var', 'features.2.conv.7.num_batches_tracked', 'features.3.conv.0.weight', 'features.3.conv.1.weight', 'features.3.conv.1.bias', 'features.3.conv.1.running_mean', 'features.3.conv.1.running_var', 'features.3.conv.1.num_batches_tracked', 'features.3.conv.3.weight', 'features.3.conv.4.weight', 'features.3.conv.4.bias', 'features.3.conv.4.running_mean', 'features.3.conv.4.running_var', 'features.3.conv.4.num_batches_tracked', 'features.3.conv.6.weight', 'features.3.conv.7.weight', 'features.3.conv.7.bias', 'features.3.conv.7.running_mean', 'features.3.conv.7.running_var', 'features.3.conv.7.num_batches_tracked', 'features.4.conv.0.weight', 'features.4.conv.1.weight', 'features.4.conv.1.bias', 'features.4.conv.1.running_mean', 'features.4.conv.1.running_var', 'features.4.conv.1.num_batches_tracked', 'features.4.conv.3.weight', 'features.4.conv.4.weight', 'features.4.conv.4.bias', 'features.4.conv.4.running_mean', 'features.4.conv.4.running_var', 'features.4.conv.4.num_batches_tracked', 'features.4.conv.6.weight', 'features.4.conv.7.weight', 'features.4.conv.7.bias', 'features.4.conv.7.running_mean', 'features.4.conv.7.running_var', 'features.4.conv.7.num_batches_tracked', 'features.5.conv.0.weight', 'features.5.conv.1.weight', 'features.5.conv.1.bias', 'features.5.conv.1.running_mean', 'features.5.conv.1.running_var', 'features.5.conv.1.num_batches_tracked', 'features.5.conv.3.weight', 'features.5.conv.4.weight', 'features.5.conv.4.bias', 'features.5.conv.4.running_mean', 'features.5.conv.4.running_var', 'features.5.conv.4.num_batches_tracked', 'features.5.conv.6.weight', 'features.5.conv.7.weight', 'features.5.conv.7.bias', 'features.5.conv.7.running_mean', 'features.5.conv.7.running_var', 'features.5.conv.7.num_batches_tracked', 'features.6.conv.0.weight', 'features.6.conv.1.weight', 'features.6.conv.1.bias', 'features.6.conv.1.running_mean', 'features.6.conv.1.running_var', 'features.6.conv.1.num_batches_tracked', 'features.6.conv.3.weight', 'features.6.conv.4.weight', 'features.6.conv.4.bias', 'features.6.conv.4.running_mean', 'features.6.conv.4.running_var', 'features.6.conv.4.num_batches_tracked', 'features.6.conv.6.weight', 'features.6.conv.7.weight', 'features.6.conv.7.bias', 'features.6.conv.7.running_mean', 'features.6.conv.7.running_var', 'features.6.conv.7.num_batches_tracked', 'features.7.conv.0.weight', 'features.7.conv.1.weight', 'features.7.conv.1.bias', 'features.7.conv.1.running_mean', 'features.7.conv.1.running_var', 'features.7.conv.1.num_batches_tracked', 'features.7.conv.3.weight', 'features.7.conv.4.weight', 'features.7.conv.4.bias', 'features.7.conv.4.running_mean', 'features.7.conv.4.running_var', 'features.7.conv.4.num_batches_tracked', 'features.7.conv.6.weight', 'features.7.conv.7.weight', 'features.7.conv.7.bias', 'features.7.conv.7.running_mean', 'features.7.conv.7.running_var', 'features.7.conv.7.num_batches_tracked', 'features.8.conv.0.weight', 'features.8.conv.1.weight', 'features.8.conv.1.bias', 'features.8.conv.1.running_mean', 'features.8.conv.1.running_var', 'features.8.conv.1.num_batches_tracked', 'features.8.conv.3.weight', 'features.8.conv.4.weight', 'features.8.conv.4.bias', 'features.8.conv.4.running_mean', 'features.8.conv.4.running_var', 'features.8.conv.4.num_batches_tracked', 'features.8.conv.6.weight', 'features.8.conv.7.weight', 'features.8.conv.7.bias', 'features.8.conv.7.running_mean', 'features.8.conv.7.running_var', 'features.8.conv.7.num_batches_tracked', 'features.9.conv.0.weight', 'features.9.conv.1.weight', 'features.9.conv.1.bias', 'features.9.conv.1.running_mean', 'features.9.conv.1.running_var', 'features.9.conv.1.num_batches_tracked', 'features.9.conv.3.weight', 'features.9.conv.4.weight', 'features.9.conv.4.bias', 'features.9.conv.4.running_mean', 'features.9.conv.4.running_var', 'features.9.conv.4.num_batches_tracked', 'features.9.conv.6.weight', 'features.9.conv.7.weight', 'features.9.conv.7.bias', 'features.9.conv.7.running_mean', 'features.9.conv.7.running_var', 'features.9.conv.7.num_batches_tracked', 'features.10.conv.0.weight', 'features.10.conv.1.weight', 'features.10.conv.1.bias', 'features.10.conv.1.running_mean', 'features.10.conv.1.running_var', 'features.10.conv.1.num_batches_tracked', 'features.10.conv.3.weight', 'features.10.conv.4.weight', 'features.10.conv.4.bias', 'features.10.conv.4.running_mean', 'features.10.conv.4.running_var', 'features.10.conv.4.num_batches_tracked', 'features.10.conv.6.weight', 'features.10.conv.7.weight', 'features.10.conv.7.bias', 'features.10.conv.7.running_mean', 'features.10.conv.7.running_var', 'features.10.conv.7.num_batches_tracked', 'features.11.conv.0.weight', 'features.11.conv.1.weight', 'features.11.conv.1.bias', 'features.11.conv.1.running_mean', 'features.11.conv.1.running_var', 'features.11.conv.1.num_batches_tracked', 'features.11.conv.3.weight', 'features.11.conv.4.weight', 'features.11.conv.4.bias', 'features.11.conv.4.running_mean', 'features.11.conv.4.running_var', 'features.11.conv.4.num_batches_tracked', 'features.11.conv.6.weight', 'features.11.conv.7.weight', 'features.11.conv.7.bias', 'features.11.conv.7.running_mean', 'features.11.conv.7.running_var', 'features.11.conv.7.num_batches_tracked', 'features.12.conv.0.weight', 'features.12.conv.1.weight', 'features.12.conv.1.bias', 'features.12.conv.1.running_mean', 'features.12.conv.1.running_var', 'features.12.conv.1.num_batches_tracked', 'features.12.conv.3.weight', 'features.12.conv.4.weight', 'features.12.conv.4.bias', 'features.12.conv.4.running_mean', 'features.12.conv.4.running_var', 'features.12.conv.4.num_batches_tracked', 'features.12.conv.6.weight', 'features.12.conv.7.weight', 'features.12.conv.7.bias', 'features.12.conv.7.running_mean', 'features.12.conv.7.running_var', 'features.12.conv.7.num_batches_tracked', 'features.13.conv.0.weight', 'features.13.conv.1.weight', 'features.13.conv.1.bias', 'features.13.conv.1.running_mean', 'features.13.conv.1.running_var', 'features.13.conv.1.num_batches_tracked', 'features.13.conv.3.weight', 'features.13.conv.4.weight', 'features.13.conv.4.bias', 'features.13.conv.4.running_mean', 'features.13.conv.4.running_var', 'features.13.conv.4.num_batches_tracked', 'features.13.conv.6.weight', 'features.13.conv.7.weight', 'features.13.conv.7.bias', 'features.13.conv.7.running_mean', 'features.13.conv.7.running_var', 'features.13.conv.7.num_batches_tracked', 'features.14.conv.0.weight', 'features.14.conv.1.weight', 'features.14.conv.1.bias', 'features.14.conv.1.running_mean', 'features.14.conv.1.running_var', 'features.14.conv.1.num_batches_tracked', 'features.14.conv.3.weight', 'features.14.conv.4.weight', 'features.14.conv.4.bias', 'features.14.conv.4.running_mean', 'features.14.conv.4.running_var', 'features.14.conv.4.num_batches_tracked', 'features.14.conv.6.weight', 'features.14.conv.7.weight', 'features.14.conv.7.bias', 'features.14.conv.7.running_mean', 'features.14.conv.7.running_var', 'features.14.conv.7.num_batches_tracked', 'features.15.conv.0.weight', 'features.15.conv.1.weight', 'features.15.conv.1.bias', 'features.15.conv.1.running_mean', 'features.15.conv.1.running_var', 'features.15.conv.1.num_batches_tracked', 'features.15.conv.3.weight', 'features.15.conv.4.weight', 'features.15.conv.4.bias', 'features.15.conv.4.running_mean', 'features.15.conv.4.running_var', 'features.15.conv.4.num_batches_tracked', 'features.15.conv.6.weight', 'features.15.conv.7.weight', 'features.15.conv.7.bias', 'features.15.conv.7.running_mean', 'features.15.conv.7.running_var', 'features.15.conv.7.num_batches_tracked', 'features.16.conv.0.weight', 'features.16.conv.1.weight', 'features.16.conv.1.bias', 'features.16.conv.1.running_mean', 'features.16.conv.1.running_var', 'features.16.conv.1.num_batches_tracked', 'features.16.conv.3.weight', 'features.16.conv.4.weight', 'features.16.conv.4.bias', 'features.16.conv.4.running_mean', 'features.16.conv.4.running_var', 'features.16.conv.4.num_batches_tracked', 'features.16.conv.6.weight', 'features.16.conv.7.weight', 'features.16.conv.7.bias', 'features.16.conv.7.running_mean', 'features.16.conv.7.running_var', 'features.16.conv.7.num_batches_tracked', 'features.17.conv.0.weight', 'features.17.conv.1.weight', 'features.17.conv.1.bias', 'features.17.conv.1.running_mean', 'features.17.conv.1.running_var', 'features.17.conv.1.num_batches_tracked', 'features.17.conv.3.weight', 'features.17.conv.4.weight', 'features.17.conv.4.bias', 'features.17.conv.4.running_mean', 'features.17.conv.4.running_var', 'features.17.conv.4.num_batches_tracked', 'features.17.conv.6.weight', 'features.17.conv.7.weight', 'features.17.conv.7.bias', 'features.17.conv.7.running_mean', 'features.17.conv.7.running_var', 'features.17.conv.7.num_batches_tracked', 'features.18.0.weight', 'features.18.1.weight', 'features.18.1.bias', 'features.18.1.running_mean', 'features.18.1.running_var', 'features.18.1.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(net_1.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
